{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vBF1eI8W9FR"
      },
      "source": [
        "** JM**\n",
        "Máster Data Science ENAE CURSO 2024/2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W96Qar7MXX9K"
      },
      "source": [
        "# 0. Previa. Librerías generales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "vJZWQH4uGUCY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow=='2.3.0' keras=='2.3.1' numpy=='1.18.5'\n",
        "!pip install ydata-profiling --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "rEOLvFJtHlgx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM, GRU\n",
        "import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from ydata_profiling import ProfileReport\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.rc(\"figure, fgsize=(16, 9)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk5AkyRYZJuT"
      },
      "source": [
        "\n",
        "# 1. Cargar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce9vwuYAX2AF",
        "outputId": "6c5ffb6f-8557-444d-ae9a-535c7426b481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPmO7-bgcIv",
        "outputId": "07d6a764-ef6d-45bb-c014-23dad0da9612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2025_Fine_Tunning_LLMs_con_LoRA.ipynb\n",
            " 2025_RAG_Example.ipynb\n",
            " airfoil_self_noise.csv\n",
            " Artiles_Suarez_JoseMiguel_CasopracticoFinal_DL.ipynb\n",
            " EjemploSimilarEntrega.ipynb\n",
            " ENAE_Agents_CrewAI.ipynb\n",
            " model.h5\n",
            "'Primera_Red_Neuronal copia.ipynb'\n",
            " test_v2.csv\n",
            " train_v2.csv\n"
          ]
        }
      ],
      "source": [
        "!ls \"/content/drive/MyDrive/Colab Notebooks/01-DL-ML\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "eXTkhlNxhkLI"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/Colab Notebooks/01-DL-ML/train_v2.csv\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/01-DL-ML/test_v2.csv\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {
        "id": "CgVzLXYK0Q3K"
      },
      "outputs": [],
      "source": [
        "# Cargar los datos de entrenamiento y test\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/01-DL-ML/test_v2.csv\", header=0)\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/01-DL-ML/train_v2.csv\", header=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "islkLn5ImrZo"
      },
      "source": [
        "Apunte: fundamental a la hora de cargar el archivo .csv (header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfDCNE7F0qIA"
      },
      "source": [
        "# 2. Análisis exploratorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9Ft-WMHpYkO",
        "outputId": "3693aa07-756a-4375-fdf7-5bafd4db8b3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores faltantes en train_df:\n",
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      173\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n",
            "Valores faltantes en test_df:\n",
            "Id                0\n",
            "MSSubClass        0\n",
            "MSZoning          0\n",
            "LotFrontage      86\n",
            "LotArea           0\n",
            "                 ..\n",
            "MoSold            0\n",
            "YrSold            0\n",
            "SaleType          0\n",
            "SaleCondition     0\n",
            "SalePrice         0\n",
            "Length: 81, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Verificar valores faltantes en train_df\n",
        "print(\"Valores faltantes en train_df:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "# Verificar valores faltantes en test_df\n",
        "print(\"Valores faltantes en test_df:\")\n",
        "print(test_df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WKZqxxa0sgw",
        "outputId": "26417f66-678c-4646-c292-72c7615e2a88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos de entrenamiento:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2008        WD         Normal     208500  \n",
            "1   2007        WD         Normal     181500  \n",
            "2   2008        WD         Normal     223500  \n",
            "3   2006        WD        Abnorml     140000  \n",
            "4   2008        WD         Normal     250000  \n",
            "\n",
            "[5 rows x 81 columns]\n",
            "\n",
            "Datos de prueba:\n",
            "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0  1000          20       RL         64.0     6762   Pave   NaN      Reg   \n",
            "1  1001          20       RL         74.0    10206   Pave   NaN      Reg   \n",
            "2  1002          30       RL         60.0     5400   Pave   NaN      Reg   \n",
            "3  1003          20       RL         75.0    11957   Pave   NaN      IR1   \n",
            "4  1004          90       RL          NaN    11500   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
            "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
            "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      7   \n",
            "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      1   \n",
            "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      7   \n",
            "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      6   \n",
            "\n",
            "  YrSold  SaleType  SaleCondition  SalePrice  \n",
            "0   2010        WD         Normal     206000  \n",
            "1   2009        WD         Normal      82000  \n",
            "2   2007        WD        Abnorml      86000  \n",
            "3   2008        WD         Normal     232000  \n",
            "4   2007        WD         Normal     136905  \n",
            "\n",
            "[5 rows x 81 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Ver las primeras filas de ambos datasets\n",
        "print(\"Datos de entrenamiento:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nDatos de prueba:\")\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fImFv6qMnfcO",
        "outputId": "7d9d301d-0893-497c-e61e-15945e514aff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train y y_train han sido creados correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Separar características (X_train) y variable objetivo (y_train)\n",
        "X_train = train_df.drop(columns=['SalePrice'])  # Características\n",
        "y_train = train_df['SalePrice']                # Variable objetivo\n",
        "\n",
        "print(\"X_train y y_train han sido creados correctamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy9fXaS5Skq8",
        "outputId": "4988e3a5-f162-4112-c2ce-144d8e8c765d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_test ha sido creado correctamente.\n"
          ]
        }
      ],
      "source": [
        "# Asignar test_df a X_test\n",
        "X_test = test_df\n",
        "\n",
        "print(\"X_test ha sido creado correctamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ueAcgFSnaC",
        "outputId": "ddcd393f-bb1c-44cb-8f12-ea22b43b5f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Estructura de X_test ajustada para coincidir con X_train.\n"
          ]
        }
      ],
      "source": [
        "# Asegurarnos de que X_test tenga las mismas columnas que X_train\n",
        "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
        "for col in missing_cols:\n",
        "    X_test[col] = 0  # Agregar columnas faltantes con valor 0\n",
        "\n",
        "# Reordenamiento de las columnas de X_test para que coincidan con X_train\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "print(\"Estructura de X_test ajustada para coincidir con X_train.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GnBQFJ81ILk",
        "outputId": "902eede0-202e-47a8-8881-6f8d49131aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Valores faltantes en train:\n",
            "Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      173\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n",
            "\n",
            "Valores faltantes en test:\n",
            "Id                0\n",
            "MSSubClass        0\n",
            "MSZoning          0\n",
            "LotFrontage      86\n",
            "LotArea           0\n",
            "                 ..\n",
            "MoSold            0\n",
            "YrSold            0\n",
            "SaleType          0\n",
            "SaleCondition     0\n",
            "SalePrice         0\n",
            "Length: 81, dtype: int64\n",
            "\n",
            "Filas duplicadas en train: 0\n",
            "Filas duplicadas en test: 0\n",
            "\n",
            "Estadísticos de train:\n",
            "               Id  MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
            "count  999.000000  999.000000   826.000000     999.000000   999.000000   \n",
            "mean   500.000000   56.916917    69.962470   10695.109109     6.124124   \n",
            "std    288.530761   42.261403    23.215821   11417.706546     1.383632   \n",
            "min      1.000000   20.000000    21.000000    1300.000000     1.000000   \n",
            "25%    250.500000   20.000000    60.000000    7589.000000     5.000000   \n",
            "50%    500.000000   50.000000    70.000000    9452.000000     6.000000   \n",
            "75%    749.500000   70.000000    80.000000   11632.000000     7.000000   \n",
            "max    999.000000  190.000000   313.000000  215245.000000    10.000000   \n",
            "\n",
            "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
            "count   999.000000   999.000000    999.000000   993.000000   999.000000  ...   \n",
            "mean      5.587588  1971.598599   1985.258258   109.311178   444.972973  ...   \n",
            "std       1.109300    30.003240     20.411974   188.961644   442.550816  ...   \n",
            "min       1.000000  1880.000000   1950.000000     0.000000     0.000000  ...   \n",
            "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
            "50%       5.000000  1974.000000   1994.000000     0.000000   384.000000  ...   \n",
            "75%       6.000000  2000.000000   2004.000000   175.000000   726.000000  ...   \n",
            "max       9.000000  2010.000000   2010.000000  1600.000000  2260.000000  ...   \n",
            "\n",
            "       WoodDeckSF  OpenPorchSF  EnclosedPorch   3SsnPorch  ScreenPorch  \\\n",
            "count  999.000000   999.000000     999.000000  999.000000   999.000000   \n",
            "mean    97.345345    47.655656      21.434434    3.706707    15.070070   \n",
            "std    124.454384    68.021301      60.723143   30.930996    55.493478   \n",
            "min      0.000000     0.000000       0.000000    0.000000     0.000000   \n",
            "25%      0.000000     0.000000       0.000000    0.000000     0.000000   \n",
            "50%      0.000000    24.000000       0.000000    0.000000     0.000000   \n",
            "75%    171.500000    70.000000       0.000000    0.000000     0.000000   \n",
            "max    857.000000   523.000000     552.000000  508.000000   410.000000   \n",
            "\n",
            "         PoolArea       MiscVal      MoSold       YrSold      SalePrice  \n",
            "count  999.000000    999.000000  999.000000   999.000000     999.000000  \n",
            "mean     1.161161     45.429429    6.311311  2007.827828  182260.711712  \n",
            "std     26.116378    525.710557    2.688986     1.325859   80327.919925  \n",
            "min      0.000000      0.000000    1.000000  2006.000000   34900.000000  \n",
            "25%      0.000000      0.000000    5.000000  2007.000000  130000.000000  \n",
            "50%      0.000000      0.000000    6.000000  2008.000000  163990.000000  \n",
            "75%      0.000000      0.000000    8.000000  2009.000000  215000.000000  \n",
            "max    648.000000  15500.000000   12.000000  2010.000000  755000.000000  \n",
            "\n",
            "[8 rows x 38 columns]\n",
            "\n",
            "Estadísticos de test:\n",
            "                Id  MSSubClass  LotFrontage       LotArea  OverallQual  \\\n",
            "count   461.000000  461.000000   375.000000    461.000000   461.000000   \n",
            "mean   1230.000000   56.854664    70.242667  10130.488069     6.045553   \n",
            "std     133.223496   42.431255    26.519336   5738.877250     1.381590   \n",
            "min    1000.000000   20.000000    21.000000   1477.000000     2.000000   \n",
            "25%    1115.000000   20.000000    58.500000   7500.000000     5.000000   \n",
            "50%    1230.000000   50.000000    68.000000   9503.000000     6.000000   \n",
            "75%    1345.000000   70.000000    80.000000  11500.000000     7.000000   \n",
            "max    1460.000000  190.000000   313.000000  63887.000000    10.000000   \n",
            "\n",
            "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
            "count   461.000000   461.000000    461.000000   459.000000   461.000000  ...   \n",
            "mean      5.548807  1970.550976   1984.015184    91.514161   440.750542  ...   \n",
            "std       1.121094    30.651692     21.139850   162.208547   484.642433  ...   \n",
            "min       3.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
            "25%       5.000000  1950.000000   1966.000000     0.000000     0.000000  ...   \n",
            "50%       5.000000  1971.000000   1992.000000     0.000000   378.000000  ...   \n",
            "75%       6.000000  2000.000000   2004.000000   145.000000   694.000000  ...   \n",
            "max       9.000000  2009.000000   2009.000000  1378.000000  5644.000000  ...   \n",
            "\n",
            "       WoodDeckSF  OpenPorchSF  EnclosedPorch   3SsnPorch  ScreenPorch  \\\n",
            "count  461.000000   461.000000     461.000000  461.000000   461.000000   \n",
            "mean    87.524946    44.503254      23.080260    2.765727    15.041215   \n",
            "std    127.110710    62.276195      62.020123   25.491972    56.385749   \n",
            "min      0.000000     0.000000       0.000000    0.000000     0.000000   \n",
            "25%      0.000000     0.000000       0.000000    0.000000     0.000000   \n",
            "50%      0.000000    25.000000       0.000000    0.000000     0.000000   \n",
            "75%    161.000000    64.000000       0.000000    0.000000     0.000000   \n",
            "max    736.000000   547.000000     330.000000  304.000000   480.000000   \n",
            "\n",
            "         PoolArea      MiscVal      MoSold       YrSold      SalePrice  \n",
            "count  461.000000   461.000000  461.000000   461.000000     461.000000  \n",
            "mean     6.221258    39.284165    6.344902  2007.789588  178018.427332  \n",
            "std     60.187451   425.503956    2.737883     1.333995   77495.649811  \n",
            "min      0.000000     0.000000    1.000000  2006.000000   52500.000000  \n",
            "25%      0.000000     0.000000    5.000000  2007.000000  129000.000000  \n",
            "50%      0.000000     0.000000    6.000000  2008.000000  162000.000000  \n",
            "75%      0.000000     0.000000    8.000000  2009.000000  206900.000000  \n",
            "max    738.000000  8300.000000   12.000000  2010.000000  745000.000000  \n",
            "\n",
            "[8 rows x 38 columns]\n"
          ]
        }
      ],
      "source": [
        "#Realizaremos un análisis exploratorio inicial para comprender mejor los datos. Esto incluye:\n",
        "\n",
        "# Buscar valores faltantes.\n",
        "# Detectar filas duplicadas.\n",
        "# Calcular estadísticos descriptivos\n",
        "\n",
        "# Verificar si hay valores faltantes\n",
        "print(\"\\nValores faltantes en train:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "print(\"\\nValores faltantes en test:\")\n",
        "print(test_df.isnull().sum())\n",
        "\n",
        "# Verificar si hay filas duplicadas\n",
        "print(\"\\nFilas duplicadas en train:\", train_df.duplicated().sum())\n",
        "print(\"Filas duplicadas en test:\", test_df.duplicated().sum())\n",
        "\n",
        "# Estadísticos\n",
        "print(\"\\nEstadísticos de train:\")\n",
        "print(train_df.describe())\n",
        "\n",
        "print(\"\\nEstadísticos de test:\")\n",
        "print(test_df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1ITvmcg1oen"
      },
      "source": [
        "# 3. Ingeniería de variables: crear una variable (OPCIONAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjhxOaHa1s7g"
      },
      "source": [
        "Voy a crear una variable ficticia con los valores de la columna Yrsold, con la idea de que a más nueva sea la vivienda, multiplique algo su valor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h6GjC09z2wCO",
        "outputId": "b0beb7d8-1661-4f99-8621-dec8952886f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores únicos en la columna YrSold:\n",
            "[2008 2007 2006 2009 2010]\n",
            "\n",
            "Valores únicos ordenados:\n",
            "[np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2010)]\n"
          ]
        }
      ],
      "source": [
        "# Ver los valores únicos en la columna YrSold\n",
        "unique_years_sold = train_df['YrSold'].unique()\n",
        "\n",
        "print(\"Valores únicos en la columna YrSold:\")\n",
        "print(unique_years_sold)\n",
        "\n",
        "# También puedes ordenar los valores únicos para mayor claridad\n",
        "sorted_years_sold = sorted(unique_years_sold)\n",
        "print(\"\\nValores únicos ordenados:\")\n",
        "print(sorted_years_sold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ovW7Ejl3mcH"
      },
      "source": [
        "Ahora vamos a crear una variable ficticia que de valor a las casas nuevas, dandole una puntuación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RoAVYM7qsI3",
        "outputId": "b47496c0-0a3e-4a26-fb30-4da823dd51c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variable continua 'House_Newness_Score' creada correctamente.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Cálculo de la antigüedad de la casa\n",
        "train_df['House_Age'] = train_df['YrSold'] - train_df['YearBuilt']\n",
        "test_df['House_Age'] = test_df['YrSold'] - test_df['YearBuilt']\n",
        "\n",
        "# Definir un parámetro de depreciación\n",
        "k = 0.05  # Este valor se puede modificar según lo que se estime\n",
        "\n",
        "# Crear el score de \"Novedad (Newness)\" usando una función exponencial\n",
        "train_df['House_Newness_Score'] = np.exp(-k * train_df['House_Age'])\n",
        "test_df['House_Newness_Score'] = np.exp(-k * test_df['House_Age'])\n",
        "\n",
        "print(\"Variable continua 'House_Newness_Score' creada correctamente.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lwRWBXmrAOJ",
        "outputId": "01fb2ed4-de5d-42b7-ed5f-aa204934646a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   YearBuilt  YrSold  House_Age  House_Newness_Score\n",
            "0       2003    2008          5             0.778801\n",
            "1       1976    2007         31             0.212248\n",
            "2       2001    2008          7             0.704688\n",
            "3       1915    2006         91             0.010567\n",
            "4       2000    2008          8             0.670320\n",
            "\n",
            "Resumen estadístico de 'House_Newness_Score':\n",
            "count    999.000000\n",
            "mean       0.356517\n",
            "std        0.347636\n",
            "min        0.001581\n",
            "25%        0.067206\n",
            "50%        0.182684\n",
            "75%        0.670320\n",
            "max        1.000000\n",
            "Name: House_Newness_Score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Ver las primeras filas del DataFrame con la nueva columna\n",
        "print(train_df[['YearBuilt', 'YrSold', 'House_Age', 'House_Newness_Score']].head())\n",
        "\n",
        "# Resumen estadístico de la nueva variable\n",
        "newness_summary = train_df['House_Newness_Score'].describe()\n",
        "print(\"\\nResumen estadístico de 'House_Newness_Score':\")\n",
        "print(newness_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMMGgqQX3ruz",
        "outputId": "a065c8ea-bf45-4a97-f7a7-1558b144b1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities  ... Fence MiscFeature MiscVal MoSold YrSold SaleType  \\\n",
            "0         Lvl    AllPub  ...   NaN         NaN       0      2   2008       WD   \n",
            "1         Lvl    AllPub  ...   NaN         NaN       0      5   2007       WD   \n",
            "2         Lvl    AllPub  ...   NaN         NaN       0      9   2008       WD   \n",
            "3         Lvl    AllPub  ...   NaN         NaN       0      2   2006       WD   \n",
            "4         Lvl    AllPub  ...   NaN         NaN       0     12   2008       WD   \n",
            "\n",
            "  SaleCondition  SalePrice  House_Age  House_Newness_Score  \n",
            "0        Normal     208500          5             0.778801  \n",
            "1        Normal     181500         31             0.212248  \n",
            "2        Normal     223500          7             0.704688  \n",
            "3       Abnorml     140000         91             0.010567  \n",
            "4        Normal     250000          8             0.670320  \n",
            "\n",
            "[5 rows x 83 columns]\n"
          ]
        }
      ],
      "source": [
        "#Ahora planteamos la operación similar con la variable SaleCondition\n",
        "\n",
        "# Ver las rimeras filas para identificar las columnas\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpbvXeyB5BMi",
        "outputId": "a6e44081-1241-4253-fdb6-74e9e3a3462d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores únicos en la columna SaleCondition:\n",
            "['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n"
          ]
        }
      ],
      "source": [
        "#Comprobamos la columna\n",
        "\n",
        "# Acceder a la columna SaleCondition por su nombre\n",
        "unique_sale_conditions = train_df['SaleCondition'].unique()\n",
        "\n",
        "print(\"Valores únicos en la columna SaleCondition:\")\n",
        "print(unique_sale_conditions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KxFKayY6Kae"
      },
      "source": [
        "Observando la tipología de los datos, vamos a crear una variable dummy para cada una situación distinta de las viviendas, y luego la incluiremos en el modelo de regresión\n",
        "\n",
        "\n",
        "*   Normal: venta estandár\n",
        "*   Abnormal: venta fuera de lo común, situaciones especiales\n",
        "*   Partial: venta parcial\n",
        "*   AdjLand: tiene terrenos anexos adyacentes\n",
        "*   Alloca: operación entre partes relacionadas (empresas, familias), desvirtua el análisis\n",
        "*   Family: la propiedad fue transferida dentro de la familia\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae-GjB5h7Df4",
        "outputId": "a20ef6de-a13e-45ff-a684-4a7bb68564bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  SaleCondition  SaleConditionImpacto\n",
            "0        Normal                   1.0\n",
            "1        Normal                   1.0\n",
            "2        Normal                   1.0\n",
            "3       Abnorml                  -0.7\n",
            "4        Normal                   1.0\n"
          ]
        }
      ],
      "source": [
        "#Asignamos una variable numérica a cada situación posible, para visualizar el impacto sobre el precio\n",
        "\n",
        "# Mapeamos las categorías a valores numéricos\n",
        "# La asignación de los valores es parcial, teniendo en cuenta las situaciones\n",
        "# Asignamos una variable numérica a cada situación posible, para visualizar el impacto sobre el precio\n",
        "\n",
        "sale_condition_impacto = {\n",
        "    'Normal': 1.0,\n",
        "    'Abnorml': -0.7,\n",
        "    'Partial': 0.6,\n",
        "    'AdjLand': 1.5,\n",
        "    'Alloca': 0.6,\n",
        "    'Family': 0.6\n",
        "}\n",
        "\n",
        "# Usamos el nombre de la columna en lugar del índice numérico\n",
        "train_df['SaleConditionImpacto'] = train_df['SaleCondition'].map(sale_condition_impacto)\n",
        "test_df['SaleConditionImpacto'] = test_df['SaleCondition'].map(sale_condition_impacto)\n",
        "\n",
        "# Mostrar las primeras filas con la nueva variable\n",
        "print(train_df[['SaleCondition', 'SaleConditionImpacto']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWTQLlFP9-hw"
      },
      "source": [
        "# 4. Eliminar las variables de entrada no numéricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYRK--Vr-HIm"
      },
      "source": [
        "Eliminar las variables de entrada no numéricas,también está admitido utilizar técnicas de label encoder o parecidos para transformar los textos en números"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T22MHfCwC1Dr",
        "outputId": "a1fbcc18-5801-4afa-8c4a-ae42677526ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables no numéricas en train_df:\n",
            "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
            "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
            "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
            "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
            "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
            "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
            "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
            "       'SaleType', 'SaleCondition'],\n",
            "      dtype='object')\n",
            "\n",
            "Variables no numéricas en test_df:\n",
            "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
            "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
            "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
            "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
            "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
            "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
            "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
            "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
            "       'SaleType', 'SaleCondition'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Como primer paso, identificación de variables no numéricas (categóricas)\n",
        "non_numeric_cols = train_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"Variables no numéricas en train_df:\")\n",
        "print(non_numeric_cols)\n",
        "\n",
        "# Verificar si test_df tiene las mismas variables no numéricas\n",
        "test_non_numeric_cols = test_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"\\nVariables no numéricas en test_df:\")\n",
        "print(test_non_numeric_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZLwr-XEOB4"
      },
      "source": [
        "En primer lugar, se deciden eliminar las variables Alley (representa el acceso al callejón trasero, y tiene exceso de valores NA), la variable Utilities (es el acceso a los suministros, es casi una constante), la variable FireplaceQ (si disponen de chimenea, muchisimos valores NA en la columna), la variable Fence (valla, muchísimos valores NA), y la variable MiscFeature (significa cosas extras en la propiedad, presenta muchos NA en las columnas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0ThzbWUFqOc"
      },
      "source": [
        "Igualmente, se consideran eliminar las variables PoolQc (muchisimos NA), GarageQual y GarageCond (hay otras variables que relacionan el garage), BsmtFinType2 y BsmtFinType1 (el acabado del sótano, ya hay otras que lo indican), Condition1 y Condition2 (mismo caso), RoofMap (material de techo sin apenas variabilidad). Se elimina tambien LotFrontage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVOTENAKGQPH",
        "outputId": "9cdc8cdb-f6d9-4bc1-ecce-c88640bf0d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas eliminadas: ['Alley', 'Utilities', 'FireplaceQu', 'Fence', 'MiscFeature', 'PoolQC', 'GarageQual', 'GarageCond', 'BsmtFinType1', 'BsmtFinType2', 'Condition1', 'Condition2', 'RoofMatl', 'LotFrontage']\n",
            "\n",
            "Columnas en train_df después de eliminar:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
            "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
            "       'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
            "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF',\n",
            "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath',\n",
            "       'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "\n",
            "Columnas en test_df después de eliminar:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',\n",
            "       'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
            "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
            "       'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n",
            "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF',\n",
            "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath',\n",
            "       'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Lista de variables a eliminar\n",
        "columns_to_drop = [\n",
        "    'Alley', 'Utilities', 'FireplaceQu', 'Fence', 'MiscFeature',  # Variables previamente seleccionadas\n",
        "    'PoolQC', 'GarageQual', 'GarageCond', 'BsmtFinType1', 'BsmtFinType2',  # Variables adicionales\n",
        "    'Condition1', 'Condition2', 'RoofMatl','LotFrontage'\n",
        "]\n",
        "\n",
        "# Verificar si las columnas existen antes de eliminarlas\n",
        "existing_columns = [col for col in columns_to_drop if col in train_df.columns]\n",
        "\n",
        "# Eliminar las columnas de train_df y test_df\n",
        "train_df = train_df.drop(columns=existing_columns)\n",
        "test_df = test_df.drop(columns=existing_columns)\n",
        "\n",
        "print(f\"Columnas eliminadas: {existing_columns}\")\n",
        "\n",
        "# Mostrar las columnas restantes\n",
        "print(\"\\nColumnas en train_df después de eliminar:\")\n",
        "print(train_df.columns)\n",
        "\n",
        "print(\"\\nColumnas en test_df después de eliminar:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMHO0bqLG6Ic",
        "outputId": "c023b939-aebf-4705-a9bf-650a91e0dddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     YearBuilt    YrSold  House_Newness_Score\n",
            "YearBuilt             1.000000  0.009420             0.866252\n",
            "YrSold                0.009420  1.000000            -0.070018\n",
            "House_Newness_Score   0.866252 -0.070018             1.000000\n"
          ]
        }
      ],
      "source": [
        "#Antes de seguir limpiando, se comprueba la correlación de las variables ficticias\n",
        "\n",
        "print(train_df[['YearBuilt', 'YrSold', 'House_Newness_Score']].corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnaR4n6HHz94",
        "outputId": "ab537322-795a-4475-b29c-1d6880127e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables eliminadas: ['YearBuilt', 'YrSold']\n",
            "\n",
            "Columnas en train_df después de eliminar:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
            "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
            "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "\n",
            "Columnas en test_df después de eliminar:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
            "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
            "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Eliminamos variables originales\n",
        "original_vars_to_drop = ['YearBuilt', 'YrSold']\n",
        "\n",
        "# Comproba si las columnas existen antes de eliminarlas\n",
        "existing_columns = [col for col in original_vars_to_drop if col in train_df.columns]\n",
        "\n",
        "# Eliminar las columnas de train_df y test_df\n",
        "train_df = train_df.drop(columns=existing_columns)\n",
        "test_df = test_df.drop(columns=existing_columns)\n",
        "\n",
        "print(f\"Variables eliminadas: {existing_columns}\")\n",
        "\n",
        "# Mostrar las columnas restantes\n",
        "print(\"\\nColumnas en train_df después de eliminar:\")\n",
        "print(train_df.columns)\n",
        "\n",
        "print(\"\\nColumnas en test_df después de eliminar:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "Ibz9Rf63-Q1h"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Identificar columnas categóricas\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex5op-kbAu41",
        "outputId": "ad91f1aa-f5ef-4bfc-edcb-72664fe9a065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  MSZoning Street LotShape LandContour LotConfig LandSlope Neighborhood  \\\n",
            "0       RL   Pave      Reg         Lvl    Inside       Gtl      CollgCr   \n",
            "1       RL   Pave      Reg         Lvl       FR2       Gtl      Veenker   \n",
            "2       RL   Pave      IR1         Lvl    Inside       Gtl      CollgCr   \n",
            "3       RL   Pave      IR1         Lvl    Corner       Gtl      Crawfor   \n",
            "4       RL   Pave      IR1         Lvl       FR2       Gtl      NoRidge   \n",
            "\n",
            "  BldgType HouseStyle RoofStyle  ... HeatingQC CentralAir Electrical  \\\n",
            "0     1Fam     2Story     Gable  ...        Ex          Y      SBrkr   \n",
            "1     1Fam     1Story     Gable  ...        Ex          Y      SBrkr   \n",
            "2     1Fam     2Story     Gable  ...        Ex          Y      SBrkr   \n",
            "3     1Fam     2Story     Gable  ...        Gd          Y      SBrkr   \n",
            "4     1Fam     2Story     Gable  ...        Ex          Y      SBrkr   \n",
            "\n",
            "  KitchenQual Functional GarageType GarageFinish PavedDrive SaleType  \\\n",
            "0          Gd        Typ     Attchd          RFn          Y       WD   \n",
            "1          TA        Typ     Attchd          RFn          Y       WD   \n",
            "2          Gd        Typ     Attchd          RFn          Y       WD   \n",
            "3          Gd        Typ     Detchd          Unf          Y       WD   \n",
            "4          Gd        Typ     Attchd          RFn          Y       WD   \n",
            "\n",
            "  SaleCondition  \n",
            "0        Normal  \n",
            "1        Normal  \n",
            "2        Normal  \n",
            "3       Abnorml  \n",
            "4        Normal  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ],
      "source": [
        "print(train_df[categorical_cols].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8eKXQf1qdSh",
        "outputId": "64498528-966b-4d02-aa2c-7ed3fde7cf82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas en train_df:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
            "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
            "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "\n",
            "Columnas en test_df:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
            "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
            "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "Columnas en train_df después de añadir variables ficticias:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
            "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
            "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "\n",
            "Columnas en test_df después de añadir variables ficticias:\n",
            "Index(['Id', 'MSSubClass', 'MSZoning', 'LotArea', 'Street', 'LotShape',\n",
            "       'LandContour', 'LotConfig', 'LandSlope', 'Neighborhood', 'BldgType',\n",
            "       'HouseStyle', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'ExterQual',\n",
            "       'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
            "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(\"Columnas en train_df:\")\n",
        "print(train_df.columns)\n",
        "\n",
        "print(\"\\nColumnas en test_df:\")\n",
        "print(test_df.columns)\n",
        "\n",
        "print(\"Columnas en train_df después de añadir variables ficticias:\")\n",
        "print(train_df.columns)\n",
        "\n",
        "print(\"\\nColumnas en test_df después de añadir variables ficticias:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEYXXIQttiLq",
        "outputId": "a2d3df54-6cfa-44f4-ffe0-560e821abe47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La columna 'SaleConditionImpacto' existe en train_df.\n",
            "\n",
            "Primeras filas de 'SaleConditionImpacto' en train_df:\n",
            "0    1.0\n",
            "1    1.0\n",
            "2    1.0\n",
            "3   -0.7\n",
            "4    1.0\n",
            "Name: SaleConditionImpacto, dtype: float64\n",
            "\n",
            "Valores únicos en 'SaleConditionImpacto' en train_df:\n",
            "[ 1.  -0.7  0.6  1.5]\n",
            "\n",
            "La columna 'SaleConditionImpacto' existe en test_df.\n",
            "\n",
            "Primeras filas de 'SaleConditionImpacto' en test_df:\n",
            "0    1.0\n",
            "1    1.0\n",
            "2   -0.7\n",
            "3    1.0\n",
            "4    1.0\n",
            "Name: SaleConditionImpacto, dtype: float64\n",
            "\n",
            "Valores únicos en 'SaleConditionImpacto' en test_df:\n",
            "[ 1.  -0.7  0.6]\n"
          ]
        }
      ],
      "source": [
        "# Verificar si la columna 'SaleConditionImpacto' existe en train_df\n",
        "if 'SaleConditionImpacto' in train_df.columns:\n",
        "    print(\"La columna 'SaleConditionImpacto' existe en train_df.\")\n",
        "\n",
        "    # Mostrar las primeras filas de la columna\n",
        "    print(\"\\nPrimeras filas de 'SaleConditionImpacto' en train_df:\")\n",
        "    print(train_df['SaleConditionImpacto'].head())\n",
        "\n",
        "    # Mostrar los valores únicos en la columna\n",
        "    print(\"\\nValores únicos en 'SaleConditionImpacto' en train_df:\")\n",
        "    print(train_df['SaleConditionImpacto'].unique())\n",
        "else:\n",
        "    print(\"La columna 'SaleConditionImpacto' NO existe en train_df.\")\n",
        "\n",
        "# Verificar si la columna 'SaleConditionImpacto' existe en test_df\n",
        "if 'SaleConditionImpacto' in test_df.columns:\n",
        "    print(\"\\nLa columna 'SaleConditionImpacto' existe en test_df.\")\n",
        "\n",
        "    # Mostrar las primeras filas de la columna\n",
        "    print(\"\\nPrimeras filas de 'SaleConditionImpacto' en test_df:\")\n",
        "    print(test_df['SaleConditionImpacto'].head())\n",
        "\n",
        "    # Mostrar los valores únicos en la columna\n",
        "    print(\"\\nValores únicos en 'SaleConditionImpacto' en test_df:\")\n",
        "    print(test_df['SaleConditionImpacto'].unique())\n",
        "else:\n",
        "    print(\"\\nLa columna 'SaleConditionImpacto' NO existe en test_df.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg23pNBjKud_",
        "outputId": "dc8f0600-d53d-43cc-bfb8-9916becea708"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Primeras filas de train_df:\n",
            "   Id  MSSubClass MSZoning  LotArea Street LotShape LandContour LotConfig  \\\n",
            "0   1          60       RL     8450   Pave      Reg         Lvl    Inside   \n",
            "1   2          20       RL     9600   Pave      Reg         Lvl       FR2   \n",
            "2   3          60       RL    11250   Pave      IR1         Lvl    Inside   \n",
            "3   4          70       RL     9550   Pave      IR1         Lvl    Corner   \n",
            "4   5          60       RL    14260   Pave      IR1         Lvl       FR2   \n",
            "\n",
            "  LandSlope Neighborhood  ... ScreenPorch PoolArea  MiscVal  MoSold  SaleType  \\\n",
            "0       Gtl      CollgCr  ...           0        0        0       2        WD   \n",
            "1       Gtl      Veenker  ...           0        0        0       5        WD   \n",
            "2       Gtl      CollgCr  ...           0        0        0       9        WD   \n",
            "3       Gtl      Crawfor  ...           0        0        0       2        WD   \n",
            "4       Gtl      NoRidge  ...           0        0        0      12        WD   \n",
            "\n",
            "  SaleCondition SalePrice House_Age House_Newness_Score  SaleConditionImpacto  \n",
            "0        Normal    208500         5            0.778801                   1.0  \n",
            "1        Normal    181500        31            0.212248                   1.0  \n",
            "2        Normal    223500         7            0.704688                   1.0  \n",
            "3       Abnorml    140000        91            0.010567                  -0.7  \n",
            "4        Normal    250000         8            0.670320                   1.0  \n",
            "\n",
            "[5 rows x 68 columns]\n",
            "\n",
            "Primeras filas de test_df:\n",
            "     Id  MSSubClass MSZoning  LotArea Street LotShape LandContour LotConfig  \\\n",
            "0  1000          20       RL     6762   Pave      Reg         Lvl    Inside   \n",
            "1  1001          20       RL    10206   Pave      Reg         Lvl    Corner   \n",
            "2  1002          30       RL     5400   Pave      Reg         Lvl    Corner   \n",
            "3  1003          20       RL    11957   Pave      IR1         Lvl    Inside   \n",
            "4  1004          90       RL    11500   Pave      IR1         Lvl    Corner   \n",
            "\n",
            "  LandSlope Neighborhood  ... ScreenPorch PoolArea  MiscVal  MoSold  SaleType  \\\n",
            "0       Gtl      CollgCr  ...           0        0        0       2        WD   \n",
            "1       Gtl      Edwards  ...           0        0        0       7        WD   \n",
            "2       Gtl      OldTown  ...           0        0        0       1        WD   \n",
            "3       Gtl      Somerst  ...           0        0        0       7        WD   \n",
            "4       Gtl       NWAmes  ...           0        0        0       6        WD   \n",
            "\n",
            "  SaleCondition SalePrice House_Age House_Newness_Score  SaleConditionImpacto  \n",
            "0        Normal    206000         4            0.818731                   1.0  \n",
            "1        Normal     82000        57            0.057844                   1.0  \n",
            "2       Abnorml     86000        87            0.012907                  -0.7  \n",
            "3        Normal    232000         2            0.904837                   1.0  \n",
            "4        Normal    136905        31            0.212248                   1.0  \n",
            "\n",
            "[5 rows x 68 columns]\n"
          ]
        }
      ],
      "source": [
        "# Control de las primeras filas de train_df\n",
        "print(\"Primeras filas de train_df:\")\n",
        "print(train_df.head())\n",
        "\n",
        "# Control de las primeras filas de test_df\n",
        "print(\"\\nPrimeras filas de test_df:\")\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aILI5ghsCuLX"
      },
      "source": [
        "# 5.  Eliminar las variables de entrada que no tengan sentido lógico para realizar la predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5KHeZBMLT-g"
      },
      "source": [
        "Se procede a eliminar más variables que no tienen sentido en la predicción, para simplificarla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c13XnwTXs0by",
        "outputId": "31ae2f02-c5e8-449e-aa3b-7eb09ba00440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas categóricas detectadas:\n",
            "Index(['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig',\n",
            "       'LandSlope', 'Neighborhood', 'BldgType', 'HouseStyle', 'RoofStyle',\n",
            "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
            "       'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'Heating',\n",
            "       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
            "       'GarageType', 'GarageFinish', 'PavedDrive', 'SaleType',\n",
            "       'SaleCondition'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Identificar columnas categóricas\n",
        "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"Columnas categóricas detectadas:\")\n",
        "print(categorical_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "pqzY0pXrtARG"
      },
      "outputs": [],
      "source": [
        "#Debido a errores que se producen al aplicar LabelEncoder, vamos a transformar las columnas categóricas en numéricas siguiendo la estrategia anterior al crear las ficticias\n",
        "\n",
        "# Asignar valores numéricos manualmente\n",
        "material_score = {\n",
        "    'VinylSd': 5, 'MetalSd': 4, 'Wd Sdng': 3, 'HdBoard': 2, 'Plywood': 1,\n",
        "    'CBlock': 0, 'BrkFace': 4, 'AsbShng': 1, 'Stucco': 2, 'Stone': 5,\n",
        "    'ImStucc': 3, 'CemntBd': 4, 'BrkComm': 0\n",
        "}\n",
        "\n",
        "train_df['Exterior1st'] = train_df['Exterior1st'].map(material_score)\n",
        "test_df['Exterior1st'] = test_df['Exterior1st'].map(material_score)\n",
        "\n",
        "train_df['Exterior2nd'] = train_df['Exterior2nd'].map(material_score)\n",
        "test_df['Exterior2nd'] = test_df['Exterior2nd'].map(material_score)\n",
        "\n",
        "# Asignar valores numéricos manualmente (material externo de la casa)\n",
        "masonry_score = {'BrkFace': 5, 'Stone': 4, 'None': 0, 'BrkCmn': 2}\n",
        "\n",
        "train_df['MasVnrType'] = train_df['MasVnrType'].map(masonry_score)\n",
        "test_df['MasVnrType'] = test_df['MasVnrType'].map(masonry_score)\n",
        "\n",
        "# Asignar valores numéricos manualmente (valoración del estado exterior)\n",
        "quality_score = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
        "\n",
        "train_df['ExterQual'] = train_df['ExterQual'].map(quality_score)\n",
        "test_df['ExterQual'] = test_df['ExterQual'].map(quality_score)\n",
        "\n",
        "train_df['ExterCond'] = train_df['ExterCond'].map(quality_score)\n",
        "test_df['ExterCond'] = test_df['ExterCond'].map(quality_score)\n",
        "\n",
        "#Cimentación\n",
        "\n",
        "foundation_score = {'PConc': 5, 'CBlock': 3, 'BrkTil': 2, 'Slab': 1, 'Stone': 4, 'Wood': 1}\n",
        "\n",
        "train_df['Foundation'] = train_df['Foundation'].map(foundation_score)\n",
        "test_df['Foundation'] = test_df['Foundation'].map(foundation_score)\n",
        "\n",
        "#Calidades del sótano: # BsmtQual y BsmtCond\n",
        "basement_quality_score = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1, 'NA': 0}\n",
        "\n",
        "train_df['BsmtQual'] = train_df['BsmtQual'].map(basement_quality_score)\n",
        "test_df['BsmtQual'] = test_df['BsmtQual'].map(basement_quality_score)\n",
        "\n",
        "train_df['BsmtCond'] = train_df['BsmtCond'].map(basement_quality_score)\n",
        "test_df['BsmtCond'] = test_df['BsmtCond'].map(basement_quality_score)\n",
        "\n",
        "# BsmtExposure\n",
        "exposure_score = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1, 'NA': 0}\n",
        "\n",
        "train_df['BsmtExposure'] = train_df['BsmtExposure'].map(exposure_score)\n",
        "test_df['BsmtExposure'] = test_df['BsmtExposure'].map(exposure_score)\n",
        "\n",
        "#Tipos de calefacción\n",
        "\n",
        "# Eliminar Heating\n",
        "train_df = train_df.drop(columns=['Heating'], errors='ignore')\n",
        "test_df = test_df.drop(columns=['Heating'], errors='ignore')\n",
        "\n",
        "# Convertir HeatingQC\n",
        "heating_quality_score = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
        "\n",
        "train_df['HeatingQC'] = train_df['HeatingQC'].map(heating_quality_score)\n",
        "test_df['HeatingQC'] = test_df['HeatingQC'].map(heating_quality_score)\n",
        "\n",
        "#Electricidad\n",
        "electrical_score = {'SBrkr': 5, 'FuseA': 3, 'FuseF': 2, 'FuseP': 1, 'Mix': 0}\n",
        "\n",
        "train_df['Electrical'] = train_df['Electrical'].map(electrical_score)\n",
        "test_df['Electrical'] = test_df['Electrical'].map(electrical_score)\n",
        "\n",
        "#Cocina\n",
        "\n",
        "train_df['KitchenQual'] = train_df['KitchenQual'].map(quality_score)\n",
        "test_df['KitchenQual'] = test_df['KitchenQual'].map(quality_score)\n",
        "\n",
        "#Funcionalidad de la vivienda\n",
        "\n",
        "functional_score = {'Typ': 8, 'Min1': 7, 'Min2': 6, 'Mod': 5, 'Maj1': 4, 'Maj2': 3, 'Sev': 2, 'Sal': 1}\n",
        "\n",
        "train_df['Functional'] = train_df['Functional'].map(functional_score)\n",
        "test_df['Functional'] = test_df['Functional'].map(functional_score)\n",
        "\n",
        "#Cuestiones del garage\n",
        "\n",
        "garage_type_score = {'Attchd': 5, 'Detchd': 4, 'BuiltIn': 6, 'Basment': 3, 'CarPort': 2, '2Types': 7, 'NA': 0}\n",
        "garage_finish_score = {'Fin': 3, 'RFn': 2, 'Unf': 1, 'NA': 0}\n",
        "paved_drive_score = {'Y': 3, 'P': 2, 'N': 1}\n",
        "\n",
        "train_df['GarageType'] = train_df['GarageType'].map(garage_type_score)\n",
        "test_df['GarageType'] = test_df['GarageType'].map(garage_type_score)\n",
        "\n",
        "train_df['GarageFinish'] = train_df['GarageFinish'].map(garage_finish_score)\n",
        "test_df['GarageFinish'] = test_df['GarageFinish'].map(garage_finish_score)\n",
        "\n",
        "train_df['PavedDrive'] = train_df['PavedDrive'].map(paved_drive_score)\n",
        "test_df['PavedDrive'] = test_df['PavedDrive'].map(paved_drive_score)\n",
        "\n",
        "# Tipo y condiciones de la venta\n",
        "\n",
        "sale_type_score = {'WD': 5, 'New': 6, 'COD': 4, 'ConLD': 3, 'ConLI': 2, 'ConLw': 1, 'Oth': 0}\n",
        "sale_condition_score = {'Normal': 5, 'Partial': 6, 'Abnorml': 3, 'Family': 2, 'Alloca': 1, 'AdjLand': 0}\n",
        "\n",
        "train_df['SaleType'] = train_df['SaleType'].map(sale_type_score)\n",
        "test_df['SaleType'] = test_df['SaleType'].map(sale_type_score)\n",
        "\n",
        "train_df['SaleCondition'] = train_df['SaleCondition'].map(sale_condition_score)\n",
        "test_df['SaleCondition'] = test_df['SaleCondition'].map(sale_condition_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9TxNPhAGKOm",
        "outputId": "508ddd51-b726-4fd1-eb7f-e1bbcb1eb6eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas restantes en train_df después de eliminar las categóricas:\n",
            "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearRemodAdd', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
            "       'TotalBsmtSF', 'HeatingQC', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "\n",
            "Columnas restantes en test_df después de eliminar las categóricas:\n",
            "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearRemodAdd', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
            "       'TotalBsmtSF', 'HeatingQC', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Identificar columnas categóricas en train_df y test_df\n",
        "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
        "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Paso 2: Eliminar las columnas categóricas de train_df y test_df\n",
        "train_df = train_df.drop(columns=categorical_cols_train, errors='ignore')\n",
        "test_df = test_df.drop(columns=categorical_cols_test, errors='ignore')\n",
        "\n",
        "# Mostrar las columnas restantes después de la eliminación\n",
        "print(\"Columnas restantes en train_df después de eliminar las categóricas:\")\n",
        "print(train_df.columns)\n",
        "\n",
        "print(\"\\nColumnas restantes en test_df después de eliminar las categóricas:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZz7NrFcFWQ8",
        "outputId": "03610bca-a766-4721-eb51-a39037d3415b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No hay columnas categóricas en train_df.\n",
            "\n",
            "No hay columnas categóricas en test_df.\n"
          ]
        }
      ],
      "source": [
        "# Comprobamos si sobreviven columnas categóricas en train_df\n",
        "categorical_cols_train = train_df.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols_train) > 0:\n",
        "    print(\"Columnas categóricas en train_df:\")\n",
        "    print(categorical_cols_train)\n",
        "else:\n",
        "    print(\"No hay columnas categóricas en train_df.\")\n",
        "\n",
        "# Repetimos test_df\n",
        "categorical_cols_test = test_df.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols_test) > 0:\n",
        "    print(\"\\nColumnas categóricas en test_df:\")\n",
        "    print(categorical_cols_test)\n",
        "else:\n",
        "    print(\"\\nNo hay columnas categóricas en test_df.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9nipKLtvOuP",
        "outputId": "9263c49e-51a0-48b7-f1cb-fe6be6568bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Todas las columnas en train_df son numéricas.\n",
            "\n",
            "Columnas restantes en train_df:\n",
            "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearRemodAdd', 'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
            "       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
            "       'BsmtCond', 'BsmtExposure', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
            "       'TotalBsmtSF', 'HeatingQC', 'Electrical', '1stFlrSF', '2ndFlrSF',\n",
            "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
            "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageType', 'GarageYrBlt',\n",
            "       'GarageFinish', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF',\n",
            "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
            "       'MiscVal', 'MoSold', 'SaleType', 'SaleCondition', 'SalePrice',\n",
            "       'House_Age', 'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Comprobamos columnas no numéricas\n",
        "non_numeric_cols = train_df.select_dtypes(include=['object']).columns\n",
        "\n",
        "if len(non_numeric_cols) > 0:\n",
        "    print(f\"¡Advertencia! El train_df contiene columnas no numéricas:\")\n",
        "    print(non_numeric_cols)\n",
        "\n",
        "    # Eliminar columnas no numéricas\n",
        "    train_df = train_df.drop(columns=non_numeric_cols, errors='ignore')\n",
        "    test_df = test_df.drop(columns=non_numeric_cols, errors='ignore')\n",
        "\n",
        "    print(\"Columnas no numéricas eliminadas.\")\n",
        "else:\n",
        "    print(\"Todas las columnas en train_df son numéricas.\")\n",
        "\n",
        "print(\"\\nColumnas restantes en train_df:\")\n",
        "print(train_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNLq6JWpD_Tv",
        "outputId": "5d1c2463-9124-4779-cdc6-96a4aa1b6fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Primeras filas del conjunto de entrenamiento (train_df):\n",
            "   Id  MSSubClass  LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "0   1          60     8450            7            5          2003   \n",
            "1   2          20     9600            6            8          1976   \n",
            "2   3          60    11250            7            5          2002   \n",
            "3   4          70     9550            7            5          1970   \n",
            "4   5          60    14260            8            5          2000   \n",
            "\n",
            "   Exterior1st  Exterior2nd  MasVnrType  MasVnrArea  ...  ScreenPorch  \\\n",
            "0          5.0          5.0         5.0       196.0  ...            0   \n",
            "1          4.0          4.0         NaN         0.0  ...            0   \n",
            "2          5.0          5.0         5.0       162.0  ...            0   \n",
            "3          3.0          NaN         NaN         0.0  ...            0   \n",
            "4          5.0          5.0         5.0       350.0  ...            0   \n",
            "\n",
            "   PoolArea  MiscVal  MoSold  SaleType  SaleCondition  SalePrice  House_Age  \\\n",
            "0         0        0       2       5.0              5     208500          5   \n",
            "1         0        0       5       5.0              5     181500         31   \n",
            "2         0        0       9       5.0              5     223500          7   \n",
            "3         0        0       2       5.0              3     140000         91   \n",
            "4         0        0      12       5.0              5     250000          8   \n",
            "\n",
            "   House_Newness_Score  SaleConditionImpacto  \n",
            "0             0.778801                   1.0  \n",
            "1             0.212248                   1.0  \n",
            "2             0.704688                   1.0  \n",
            "3             0.010567                  -0.7  \n",
            "4             0.670320                   1.0  \n",
            "\n",
            "[5 rows x 56 columns]\n",
            "\n",
            "Primeras filas del conjunto de prueba (test_df):\n",
            "     Id  MSSubClass  LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "0  1000          20     6762            7            5          2006   \n",
            "1  1001          20    10206            3            3          1952   \n",
            "2  1002          30     5400            5            6          1950   \n",
            "3  1003          20    11957            8            5          2006   \n",
            "4  1004          90    11500            5            6          1976   \n",
            "\n",
            "   Exterior1st  Exterior2nd  MasVnrType  MasVnrArea  ...  ScreenPorch  \\\n",
            "0          5.0          5.0         4.0        24.0  ...            0   \n",
            "1          0.0          NaN         NaN         0.0  ...            0   \n",
            "2          3.0          3.0         NaN         0.0  ...            0   \n",
            "3          5.0          5.0         5.0        53.0  ...            0   \n",
            "4          5.0          5.0         5.0       164.0  ...            0   \n",
            "\n",
            "   PoolArea  MiscVal  MoSold  SaleType  SaleCondition  SalePrice  House_Age  \\\n",
            "0         0        0       2       5.0              5     206000          4   \n",
            "1         0        0       7       5.0              5      82000         57   \n",
            "2         0        0       1       5.0              3      86000         87   \n",
            "3         0        0       7       5.0              5     232000          2   \n",
            "4         0        0       6       5.0              5     136905         31   \n",
            "\n",
            "   House_Newness_Score  SaleConditionImpacto  \n",
            "0             0.818731                   1.0  \n",
            "1             0.057844                   1.0  \n",
            "2             0.012907                  -0.7  \n",
            "3             0.904837                   1.0  \n",
            "4             0.212248                   1.0  \n",
            "\n",
            "[5 rows x 56 columns]\n"
          ]
        }
      ],
      "source": [
        "#Repaso de las columnas que aún existen\n",
        "\n",
        "print(\"Primeras filas del conjunto de entrenamiento (train_df):\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nPrimeras filas del conjunto de prueba (test_df):\")\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPyj7MAmG8_q",
        "outputId": "b7ebbcf9-65dd-4771-a7a1-145e47680bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas con valores NaN en train_df:\n",
            "['Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'SaleType']\n",
            "\n",
            "Columnas con valores NaN en test_df:\n",
            "['Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'Electrical', 'GarageType', 'GarageYrBlt', 'GarageFinish', 'SaleType']\n",
            "\n",
            "Columnas restantes en train_df después de eliminar las columnas con NaN:\n",
            "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearRemodAdd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtFinSF1',\n",
            "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', 'Electrical',\n",
            "       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
            "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
            "       'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageCars',\n",
            "       'GarageArea', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
            "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
            "       'MoSold', 'SaleCondition', 'SalePrice', 'House_Age',\n",
            "       'House_Newness_Score', 'SaleConditionImpacto'],\n",
            "      dtype='object')\n",
            "\n",
            "Columnas restantes en test_df después de eliminar las columnas con NaN:\n",
            "Index(['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond',\n",
            "       'YearRemodAdd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtFinSF1',\n",
            "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', '1stFlrSF',\n",
            "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath',\n",
            "       'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
            "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageCars', 'GarageArea',\n",
            "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
            "       'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'SaleCondition',\n",
            "       'SalePrice', 'House_Age', 'House_Newness_Score',\n",
            "       'SaleConditionImpacto'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Identificar columnas con valores NaN en train_df\n",
        "nan_columns_train = train_df.columns[train_df.isnull().any()].tolist()\n",
        "print(\"Columnas con valores NaN en train_df:\")\n",
        "print(nan_columns_train)\n",
        "\n",
        "# Paso 2: Identificar columnas con valores NaN en test_df\n",
        "nan_columns_test = test_df.columns[test_df.isnull().any()].tolist()\n",
        "print(\"\\nColumnas con valores NaN en test_df:\")\n",
        "print(nan_columns_test)\n",
        "\n",
        "# Paso 3: Eliminar las columnas con valores NaN de train_df y test_df\n",
        "train_df = train_df.drop(columns=nan_columns_train, errors='ignore')\n",
        "test_df = test_df.drop(columns=nan_columns_test, errors='ignore')\n",
        "\n",
        "# Mostrar las columnas restantes después de la eliminación\n",
        "print(\"\\nColumnas restantes en train_df después de eliminar las columnas con NaN:\")\n",
        "print(train_df.columns)\n",
        "\n",
        "print(\"\\nColumnas restantes en test_df después de eliminar las columnas con NaN:\")\n",
        "print(test_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "yN2p9pH8wdy8"
      },
      "outputs": [],
      "source": [
        "# Verificar valores únicos en columnas que deberían ser categóricas\n",
        "categorical_cols_to_check = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'LotConfig']\n",
        "\n",
        "for col in categorical_cols_to_check:\n",
        "    if col in train_df.columns:\n",
        "        print(f\"Valores únicos en {col}:\")\n",
        "        print(train_df[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-EiTGTnwkS1",
        "outputId": "9a0b1845-d857-4ac4-bb49-a54adad75ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas en test_df pero no en train_df:\n",
            "set()\n",
            "Columnas en train_df pero no en test_df:\n",
            "{'Electrical'}\n"
          ]
        }
      ],
      "source": [
        "# Comparar columnas en train_df y test_df\n",
        "missing_in_train = set(test_df.columns) - set(train_df.columns)\n",
        "missing_in_test = set(train_df.columns) - set(test_df.columns)\n",
        "\n",
        "print(\"Columnas en test_df pero no en train_df:\")\n",
        "print(missing_in_train)\n",
        "\n",
        "print(\"Columnas en train_df pero no en test_df:\")\n",
        "print(missing_in_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-7Oh1HDMOyN",
        "outputId": "89edb1f3-ac21-4e37-8473-16a8b9f0f300"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SalePrice está presente en train_df.\n",
            "SalePrice está presente en test_df.\n"
          ]
        }
      ],
      "source": [
        "# Verificar si 'SalePrice' está en train_df\n",
        "if 'SalePrice' in train_df.columns:\n",
        "    print(\"SalePrice está presente en train_df.\")\n",
        "else:\n",
        "    print(\"SalePrice NO está presente en train_df.\")\n",
        "\n",
        "# Verificar si 'SalePrice' está en test_df\n",
        "if 'SalePrice' in test_df.columns:\n",
        "    print(\"SalePrice está presente en test_df.\")\n",
        "else:\n",
        "    print(\"SalePrice NO está presente en test_df.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xQR5TcSJ9eJ"
      },
      "source": [
        "# 7. Dividir los datos de entrenamiento en Train (80%) y Validation (20%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxLjKjbKK25Y",
        "outputId": "c7a9fc9a-d9ab-45b7-fcb6-7847c730341f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones de los subconjuntos:\n",
            "X_train: (799, 44)\n",
            "X_val: (200, 44)\n",
            "y_train: (799,)\n",
            "y_val: (200,)\n",
            "\n",
            "Primeras filas de X_train:\n",
            "      Id  MSSubClass  LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "778  779          90     8400            5            5          1977   \n",
            "286  287          50     9786            6            7          1981   \n",
            "165  166         190    10106            5            7          1999   \n",
            "960  961          20     7207            5            7          2008   \n",
            "493  494          20     7931            5            6          1960   \n",
            "\n",
            "     ExterQual  ExterCond  Foundation  BsmtFinSF1  ...  EnclosedPorch  \\\n",
            "778          3          3           1           0  ...              0   \n",
            "286          3          3           3         600  ...              0   \n",
            "165          3          4           2         351  ...              0   \n",
            "960          3          4           3         696  ...              0   \n",
            "493          3          3           3         374  ...              0   \n",
            "\n",
            "     3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  SaleCondition  \\\n",
            "778          0            0         0        0      10              5   \n",
            "286          0          128         0        0       6              5   \n",
            "165          0            0         0        0       9              5   \n",
            "960          0            0         0        0       2              5   \n",
            "493          0            0         0        0       6              5   \n",
            "\n",
            "     House_Age  House_Newness_Score  SaleConditionImpacto  \n",
            "778         30             0.223130                   1.0  \n",
            "286         44             0.110803                   1.0  \n",
            "165         68             0.033373                   1.0  \n",
            "960         52             0.074274                   1.0  \n",
            "493         48             0.090718                   1.0  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "Primeras filas de X_val:\n",
            "      Id  MSSubClass  LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "453  454          60     9000            8            5          2008   \n",
            "793  794          20     9158            8            5          2007   \n",
            "209  210          20     8250            6            7          1964   \n",
            "309  310          20    12378            9            5          2004   \n",
            "740  741          70     9600            5            7          2002   \n",
            "\n",
            "     ExterQual  ExterCond  Foundation  BsmtFinSF1  ...  EnclosedPorch  \\\n",
            "453          4          3           5           0  ...              0   \n",
            "793          4          3           5           0  ...              0   \n",
            "209          3          3           3         787  ...              0   \n",
            "309          4          3           5        1274  ...              0   \n",
            "740          3          4           2           0  ...            112   \n",
            "\n",
            "     3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  SaleCondition  \\\n",
            "453          0            0         0        0       6              5   \n",
            "793          0            0         0        0       6              6   \n",
            "209          0            0         0        0       7              5   \n",
            "309          0            0         0        0      11              5   \n",
            "740          0            0         0        0       5              3   \n",
            "\n",
            "     House_Age  House_Newness_Score  SaleConditionImpacto  \n",
            "453          1             0.951229                   1.0  \n",
            "793          0             1.000000                   0.6  \n",
            "209         44             0.110803                   1.0  \n",
            "309          3             0.860708                   1.0  \n",
            "740         97             0.007828                  -0.7  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "Primeros valores de y_train:\n",
            "778    144000\n",
            "286    159000\n",
            "165    127500\n",
            "960    116500\n",
            "493    155000\n",
            "Name: SalePrice, dtype: int64\n",
            "\n",
            "Primeros valores de y_val:\n",
            "453    210000\n",
            "793    225000\n",
            "209    145000\n",
            "309    360000\n",
            "740    132000\n",
            "Name: SalePrice, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Separar características (X) y variable objetivo (y)\n",
        "X = train_df.drop(columns=['SalePrice'])  # Características\n",
        "y = train_df['SalePrice']                # Variable objetivo\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento (80%) y validación (20%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "#  Dimensiones de los subconjuntos\n",
        "print(\"Dimensiones de los subconjuntos:\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_val: {X_val.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_val: {y_val.shape}\")\n",
        "\n",
        "#  Primeras filas de cada subconjunto\n",
        "print(\"\\nPrimeras filas de X_train:\")\n",
        "print(X_train.head())\n",
        "\n",
        "print(\"\\nPrimeras filas de X_val:\")\n",
        "print(X_val.head())\n",
        "\n",
        "print(\"\\nPrimeros valores de y_train:\")\n",
        "print(y_train.head())\n",
        "\n",
        "print(\"\\nPrimeros valores de y_val:\")\n",
        "print(y_val.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkvQ4yHKGXl9"
      },
      "source": [
        "#  6. Normalizar variables de entrada mediante min-max\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laUcQnMANFEg",
        "outputId": "105a147c-03a9-4619-dfa6-7960ae16539f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas numéricas detectadas: ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearRemodAdd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageCars', 'GarageArea', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'SaleCondition', 'House_Age', 'House_Newness_Score', 'SaleConditionImpacto']\n",
            "\n",
            "Primeras filas de X_train después de normalizar:\n",
            "           Id  MSSubClass   LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "778  0.779559    0.411765  0.033186     0.444444        0.500      0.450000   \n",
            "286  0.286573    0.176471  0.039664     0.555556        0.750      0.516667   \n",
            "165  0.165331    1.000000  0.041160     0.444444        0.750      0.816667   \n",
            "960  0.961924    0.000000  0.027610     0.444444        0.750      0.966667   \n",
            "493  0.493988    0.000000  0.030994     0.444444        0.625      0.166667   \n",
            "\n",
            "     ExterQual  ExterCond  Foundation  BsmtFinSF1  ...  EnclosedPorch  \\\n",
            "778   0.333333       0.50        0.00    0.000000  ...            0.0   \n",
            "286   0.333333       0.50        0.50    0.265487  ...            0.0   \n",
            "165   0.333333       0.75        0.25    0.155310  ...            0.0   \n",
            "960   0.333333       0.75        0.50    0.307965  ...            0.0   \n",
            "493   0.333333       0.50        0.50    0.165487  ...            0.0   \n",
            "\n",
            "     3SsnPorch  ScreenPorch  PoolArea  MiscVal    MoSold  SaleCondition  \\\n",
            "778        0.0     0.000000       0.0      0.0  0.818182       0.833333   \n",
            "286        0.0     0.312195       0.0      0.0  0.454545       0.833333   \n",
            "165        0.0     0.000000       0.0      0.0  0.727273       0.833333   \n",
            "960        0.0     0.000000       0.0      0.0  0.090909       0.833333   \n",
            "493        0.0     0.000000       0.0      0.0  0.454545       0.833333   \n",
            "\n",
            "     House_Age  House_Newness_Score  SaleConditionImpacto  \n",
            "778   0.232558             0.221900              0.772727  \n",
            "286   0.341085             0.109396              0.772727  \n",
            "165   0.527132             0.031843              0.772727  \n",
            "960   0.403101             0.072808              0.772727  \n",
            "493   0.372093             0.089279              0.772727  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "Primeras filas de X_val después de normalizar:\n",
            "           Id  MSSubClass   LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "453  0.453908    0.235294  0.035991     0.777778         0.50      0.966667   \n",
            "793  0.794589    0.000000  0.036729     0.777778         0.50      0.950000   \n",
            "209  0.209419    0.000000  0.032485     0.555556         0.75      0.233333   \n",
            "309  0.309619    0.000000  0.051780     0.888889         0.50      0.900000   \n",
            "740  0.741483    0.294118  0.038795     0.444444         0.75      0.866667   \n",
            "\n",
            "     ExterQual  ExterCond  Foundation  BsmtFinSF1  ...  EnclosedPorch  \\\n",
            "453   0.666667       0.50        1.00    0.000000  ...       0.000000   \n",
            "793   0.666667       0.50        1.00    0.000000  ...       0.000000   \n",
            "209   0.333333       0.50        0.50    0.348230  ...       0.000000   \n",
            "309   0.666667       0.50        1.00    0.563717  ...       0.000000   \n",
            "740   0.333333       0.75        0.25    0.000000  ...       0.202899   \n",
            "\n",
            "     3SsnPorch  ScreenPorch  PoolArea  MiscVal    MoSold  SaleCondition  \\\n",
            "453        0.0          0.0       0.0      0.0  0.454545       0.833333   \n",
            "793        0.0          0.0       0.0      0.0  0.454545       1.000000   \n",
            "209        0.0          0.0       0.0      0.0  0.545455       0.833333   \n",
            "309        0.0          0.0       0.0      0.0  0.909091       0.833333   \n",
            "740        0.0          0.0       0.0      0.0  0.363636       0.500000   \n",
            "\n",
            "     House_Age  House_Newness_Score  SaleConditionImpacto  \n",
            "453   0.007752             0.951152              0.772727  \n",
            "793   0.000000             1.000000              0.590909  \n",
            "209   0.341085             0.109396              0.772727  \n",
            "309   0.023256             0.860487              0.772727  \n",
            "740   0.751938             0.006258              0.000000  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "Valores mínimos en X_train: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Valores máximos en X_train: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "\n",
            "Valores mínimos en X_val: [ 0.01002004  0.          0.00177616  0.          0.125       0.\n",
            "  0.          0.25        0.          0.          0.          0.\n",
            "  0.          0.25       -0.25       -0.01330532  0.          0.\n",
            " -0.03479504  0.          0.          0.          0.          0.\n",
            "  0.33333333  0.         -0.11111111  0.16666667  0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.00516559  0.        ]\n",
            "Valores máximos en X_val: [0.99599198 1.         0.73710533 1.         1.         1.\n",
            " 1.         0.75       1.         0.96814159 0.76458616 0.87585616\n",
            " 0.72676232 1.         1.         0.69747899 0.76923077 0.90034965\n",
            " 0.69470925 0.66666667 1.         1.         1.         1.33333333\n",
            " 0.66666667 1.         1.22222222 1.         1.         0.75\n",
            " 0.87769784 1.         0.59393232 0.52390057 0.48550725 0.8011811\n",
            " 0.93902439 1.265625   4.42857143 1.         1.         0.7751938\n",
            " 1.         1.        ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Revisar variables numéricas en X_train y X_val\n",
        "numeric_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "print(f\"Columnas numéricas detectadas: {list(numeric_cols)}\")\n",
        "\n",
        "# Crear un MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Ajustar y transformar en X_train\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "\n",
        "# Transformar en X_val\n",
        "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
        "\n",
        "# Rresultados\n",
        "print(\"\\nPrimeras filas de X_train después de normalizar:\")\n",
        "print(X_train.head())\n",
        "\n",
        "print(\"\\nPrimeras filas de X_val después de normalizar:\")\n",
        "print(X_val.head())\n",
        "\n",
        "# Comprobación que todos los valores se encuentra en el rango [0, 1]\n",
        "print(\"\\nValores mínimos en X_train:\", X_train.min().values)\n",
        "print(\"Valores máximos en X_train:\", X_train.max().values)\n",
        "\n",
        "print(\"\\nValores mínimos en X_val:\", X_val.min().values)\n",
        "print(\"Valores máximos en X_val:\", X_val.max().values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jv5rH1LLGGj"
      },
      "source": [
        "# 8. Crear una Red Neuronal con 2 capas ocultas, 200 neuronas en cada capa y función de activación ReLu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6RF__Ku4OYC7",
        "outputId": "43d600d1-097f-4330-875f-49bf3546a964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número de características de entrada (input_dim): 44\n",
            "\n",
            "Resumen del modelo:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │         \u001b[38;5;34m9,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m40,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m201\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,401</span> (192.97 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,401\u001b[0m (192.97 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,401</span> (192.97 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,401\u001b[0m (192.97 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Librerías necesarias para predicción\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Paso 1: Verificar las dimensiones de entrada\n",
        "input_dim = X_train.shape[1]  # Número de columnas en X_train\n",
        "print(f\"Número de características de entrada (input_dim): {input_dim}\")\n",
        "\n",
        "# Definir la arquitectura del modelo secuencial\n",
        "model = Sequential()\n",
        "\n",
        "# Capa de entrada y primera capa oculta (200 neuronas, ReLU)\n",
        "model.add(Dense(200, input_dim=input_dim, activation='relu'))  # 200 neuronas, función de activación ReLU\n",
        "\n",
        "# Segunda capa oculta (200 neuronas, ReLU)\n",
        "model.add(Dense(200, activation='relu'))  # 200 neuronas, función de activación ReLU\n",
        "\n",
        "# Capa de salida (1 neurona, sin función de activación porque es regresión)\n",
        "model.add(Dense(1, activation=None))  # 1 neurona (regresión), sin función de activación\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Optimizador Adam con tasa de aprendizaje de 0.001\n",
        "    loss='mse',                          # Función de pérdida: Error Cuadrático Medio (MSE)\n",
        "    metrics=['mae']                      # Métrica adicional: Error Absoluto Medio (MAE)\n",
        ")\n",
        "\n",
        "# Resumen del modelo\n",
        "print(\"\\nResumen del modelo:\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-8wqoSBLm3j"
      },
      "source": [
        "# 9. Entrenar el algoritmo utilizando la métrica RMSE como función de coste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cPD43f0RPiDp",
        "outputId": "09591ca3-8cb7-4f9c-9597-9ceb92ff2cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columnas eliminadas por ser constantes: []\n",
            "Tipos de datos en y_train y y_val después de la conversión:\n",
            "float32 float32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │         \u001b[38;5;34m9,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m40,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m201\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,401</span> (192.97 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,401\u001b[0m (192.97 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,401</span> (192.97 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49,401\u001b[0m (192.97 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 39496577024.0000 - rmse: 198081.1875 - val_loss: 38222118912.0000 - val_rmse: 193222.3906\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39864143872.0000 - rmse: 198821.1875 - val_loss: 38181416960.0000 - val_rmse: 193117.3594\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40211349504.0000 - rmse: 199499.7656 - val_loss: 38053003264.0000 - val_rmse: 192785.6094\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39721246720.0000 - rmse: 197971.9375 - val_loss: 37759983616.0000 - val_rmse: 192026.5156\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 39649681408.0000 - rmse: 198554.3750 - val_loss: 37211009024.0000 - val_rmse: 190596.2656\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 38831570944.0000 - rmse: 196441.1875 - val_loss: 36307599360.0000 - val_rmse: 188219.2031\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 38278443008.0000 - rmse: 194565.9219 - val_loss: 34979000320.0000 - val_rmse: 184667.7031\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35023241216.0000 - rmse: 186399.7031 - val_loss: 33173106688.0000 - val_rmse: 179727.5312\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33182296064.0000 - rmse: 181671.3906 - val_loss: 30851069952.0000 - val_rmse: 173168.5938\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32022233088.0000 - rmse: 178291.8438 - val_loss: 28091256832.0000 - val_rmse: 165032.7031\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26761345024.0000 - rmse: 162459.7969 - val_loss: 24926765056.0000 - val_rmse: 155179.8281\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 26388936704.0000 - rmse: 161060.3594 - val_loss: 21448919040.0000 - val_rmse: 143571.3594\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20635617280.0000 - rmse: 142527.9531 - val_loss: 17959890944.0000 - val_rmse: 130892.0000\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17110032384.0000 - rmse: 130131.6875 - val_loss: 14566800384.0000 - val_rmse: 117248.3125\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12912809984.0000 - rmse: 112385.3828 - val_loss: 11423491072.0000 - val_rmse: 103003.9297\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12082307072.0000 - rmse: 108066.6172 - val_loss: 8738196480.0000 - val_rmse: 89051.4922\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7396397568.0000 - rmse: 84609.7812 - val_loss: 6682492928.0000 - val_rmse: 76708.6797\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5878110720.0000 - rmse: 73557.5625 - val_loss: 5217728000.0000 - val_rmse: 66655.3125\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4234615296.0000 - rmse: 62813.7344 - val_loss: 4265053184.0000 - val_rmse: 59480.9023\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4556055040.0000 - rmse: 65032.8906 - val_loss: 3722663680.0000 - val_rmse: 55340.3828\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3809096192.0000 - rmse: 59993.5234 - val_loss: 3444933632.0000 - val_rmse: 53384.5586\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3182834944.0000 - rmse: 55131.4336 - val_loss: 3308826880.0000 - val_rmse: 52579.2578\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3489569024.0000 - rmse: 57694.1797 - val_loss: 3236861696.0000 - val_rmse: 52264.1641\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3384320768.0000 - rmse: 56392.1445 - val_loss: 3203654912.0000 - val_rmse: 52137.1562\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3096005120.0000 - rmse: 54136.6953 - val_loss: 3179751680.0000 - val_rmse: 52011.4727\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3024577024.0000 - rmse: 52208.3750 - val_loss: 3158035712.0000 - val_rmse: 51878.7500\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3110719488.0000 - rmse: 54100.8828 - val_loss: 3136798464.0000 - val_rmse: 51691.0703\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2850386688.0000 - rmse: 51997.7422 - val_loss: 3115260672.0000 - val_rmse: 51500.4648\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3222362112.0000 - rmse: 55543.3984 - val_loss: 3093814528.0000 - val_rmse: 51324.9570\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3078046464.0000 - rmse: 54269.2344 - val_loss: 3071970560.0000 - val_rmse: 51099.4570\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3230578432.0000 - rmse: 55333.6289 - val_loss: 3048827136.0000 - val_rmse: 50859.2188\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3476901120.0000 - rmse: 55754.9375 - val_loss: 3027163136.0000 - val_rmse: 50641.6016\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2902996224.0000 - rmse: 52219.8828 - val_loss: 3004884480.0000 - val_rmse: 50446.8672\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3593905408.0000 - rmse: 57608.8750 - val_loss: 2982779648.0000 - val_rmse: 50240.3945\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3028442112.0000 - rmse: 53566.2539 - val_loss: 2959836160.0000 - val_rmse: 49982.9961\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3146100480.0000 - rmse: 54433.7695 - val_loss: 2936724736.0000 - val_rmse: 49727.3789\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3684212736.0000 - rmse: 58084.3164 - val_loss: 2915083264.0000 - val_rmse: 49572.0938\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2822144256.0000 - rmse: 51515.4961 - val_loss: 2891161344.0000 - val_rmse: 49291.1641\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3233595904.0000 - rmse: 54147.8555 - val_loss: 2869102080.0000 - val_rmse: 49091.7539\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2617543168.0000 - rmse: 50465.0117 - val_loss: 2846275072.0000 - val_rmse: 48834.0195\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3759580928.0000 - rmse: 57105.5781 - val_loss: 2824169472.0000 - val_rmse: 48637.4062\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2844220672.0000 - rmse: 51774.3906 - val_loss: 2801410048.0000 - val_rmse: 48402.9727\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2884561152.0000 - rmse: 51498.7031 - val_loss: 2778489088.0000 - val_rmse: 48154.5195\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3080087808.0000 - rmse: 53552.1914 - val_loss: 2755300608.0000 - val_rmse: 47940.6328\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2324894720.0000 - rmse: 47061.2578 - val_loss: 2732606208.0000 - val_rmse: 47679.7578\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3138797312.0000 - rmse: 54052.8750 - val_loss: 2710273792.0000 - val_rmse: 47494.5938\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2433680128.0000 - rmse: 48134.6094 - val_loss: 2687631104.0000 - val_rmse: 47260.5977\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3466467840.0000 - rmse: 56786.3516 - val_loss: 2665865216.0000 - val_rmse: 47088.4648\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2596218880.0000 - rmse: 48581.2461 - val_loss: 2641737984.0000 - val_rmse: 46778.1250\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2604919808.0000 - rmse: 49509.1211 - val_loss: 2618944768.0000 - val_rmse: 46548.4805\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2360308992.0000 - rmse: 46536.3359 - val_loss: 2596625664.0000 - val_rmse: 46313.2734\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2455899136.0000 - rmse: 48094.2891 - val_loss: 2574294784.0000 - val_rmse: 46119.0234\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2569680384.0000 - rmse: 48654.6211 - val_loss: 2552017664.0000 - val_rmse: 45855.7383\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2865002752.0000 - rmse: 51742.0469 - val_loss: 2529255424.0000 - val_rmse: 45642.6055\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2384453632.0000 - rmse: 46911.6211 - val_loss: 2507023616.0000 - val_rmse: 45405.8047\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2135877376.0000 - rmse: 44613.8984 - val_loss: 2485269248.0000 - val_rmse: 45168.1016\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2568579072.0000 - rmse: 49085.8633 - val_loss: 2462841344.0000 - val_rmse: 44970.2422\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1978704896.0000 - rmse: 42971.6641 - val_loss: 2441502976.0000 - val_rmse: 44731.6953\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2471217408.0000 - rmse: 47718.3047 - val_loss: 2418773248.0000 - val_rmse: 44560.6445\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2788614400.0000 - rmse: 50822.6875 - val_loss: 2396314880.0000 - val_rmse: 44306.9766\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2069175936.0000 - rmse: 43826.1719 - val_loss: 2374629888.0000 - val_rmse: 44041.6953\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1957656192.0000 - rmse: 42823.1836 - val_loss: 2353233152.0000 - val_rmse: 43829.8438\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2984926976.0000 - rmse: 51644.0547 - val_loss: 2331036672.0000 - val_rmse: 43678.2109\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2388472832.0000 - rmse: 47219.5586 - val_loss: 2308747008.0000 - val_rmse: 43429.0859\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2010574720.0000 - rmse: 43717.3594 - val_loss: 2288641536.0000 - val_rmse: 43124.7070\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2857886208.0000 - rmse: 50146.0156 - val_loss: 2265729280.0000 - val_rmse: 42971.0703\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2225966336.0000 - rmse: 46353.7773 - val_loss: 2244964608.0000 - val_rmse: 42728.0508\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1991391488.0000 - rmse: 42427.2852 - val_loss: 2223908352.0000 - val_rmse: 42484.0273\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2399084288.0000 - rmse: 47338.7383 - val_loss: 2202333952.0000 - val_rmse: 42345.5039\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2426294016.0000 - rmse: 47856.8945 - val_loss: 2181288448.0000 - val_rmse: 42082.9023\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2511858432.0000 - rmse: 48392.9453 - val_loss: 2159617024.0000 - val_rmse: 41880.4570\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2250418944.0000 - rmse: 45545.3203 - val_loss: 2139003648.0000 - val_rmse: 41653.7109\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2278730752.0000 - rmse: 45716.2852 - val_loss: 2118203136.0000 - val_rmse: 41461.4023\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2145637376.0000 - rmse: 45141.4531 - val_loss: 2097933824.0000 - val_rmse: 41255.2578\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2232464896.0000 - rmse: 45450.0312 - val_loss: 2077117824.0000 - val_rmse: 41069.1953\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2288700928.0000 - rmse: 45748.5586 - val_loss: 2057647104.0000 - val_rmse: 40815.5234\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2796531712.0000 - rmse: 50089.3555 - val_loss: 2036755456.0000 - val_rmse: 40651.2227\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2317292544.0000 - rmse: 46099.6992 - val_loss: 2017316736.0000 - val_rmse: 40454.4102\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2333063680.0000 - rmse: 47034.8125 - val_loss: 1997940608.0000 - val_rmse: 40231.0938\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2192855296.0000 - rmse: 44669.7461 - val_loss: 1977892480.0000 - val_rmse: 40048.6055\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2236987904.0000 - rmse: 44910.4844 - val_loss: 1959195392.0000 - val_rmse: 39864.2812\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1953274112.0000 - rmse: 42226.7734 - val_loss: 1941079552.0000 - val_rmse: 39666.2734\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2068339200.0000 - rmse: 43973.7812 - val_loss: 1921260032.0000 - val_rmse: 39499.4336\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1894287360.0000 - rmse: 42211.1797 - val_loss: 1901215616.0000 - val_rmse: 39365.3086\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2033728256.0000 - rmse: 44085.6445 - val_loss: 1883267712.0000 - val_rmse: 39142.4336\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1786307328.0000 - rmse: 41222.9570 - val_loss: 1865105024.0000 - val_rmse: 38987.6484\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1645170304.0000 - rmse: 38997.4844 - val_loss: 1849376256.0000 - val_rmse: 38757.0859\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1965237248.0000 - rmse: 42594.9766 - val_loss: 1828649088.0000 - val_rmse: 38659.8008\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1753825408.0000 - rmse: 40763.4492 - val_loss: 1812522112.0000 - val_rmse: 38456.8438\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2068528640.0000 - rmse: 42646.4922 - val_loss: 1793363456.0000 - val_rmse: 38341.0508\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1683088512.0000 - rmse: 39778.9219 - val_loss: 1777630080.0000 - val_rmse: 38135.6250\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1707153792.0000 - rmse: 39285.1602 - val_loss: 1759795328.0000 - val_rmse: 38014.8711\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1718453632.0000 - rmse: 39364.4258 - val_loss: 1743272320.0000 - val_rmse: 37858.4648\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1767497088.0000 - rmse: 40970.2969 - val_loss: 1726484864.0000 - val_rmse: 37709.3789\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2066554112.0000 - rmse: 43775.4922 - val_loss: 1711562240.0000 - val_rmse: 37545.9766\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1685340032.0000 - rmse: 39653.6641 - val_loss: 1696348032.0000 - val_rmse: 37383.9023\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1364418944.0000 - rmse: 35127.0469 - val_loss: 1683024256.0000 - val_rmse: 37251.8008\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1998003840.0000 - rmse: 42826.4141 - val_loss: 1663752448.0000 - val_rmse: 37182.7695\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1567902592.0000 - rmse: 38369.1836 - val_loss: 1648664448.0000 - val_rmse: 37048.5078\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2086620800.0000 - rmse: 43228.0078 - val_loss: 1634513024.0000 - val_rmse: 36891.7734\n",
            "\n",
            "Error RMSE en el conjunto de validación: 36891.77\n"
          ]
        }
      ],
      "source": [
        "#Volvemos a cargar las librerías generales\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Paso 1: Definir la función personalizada para calcular el RMSE\n",
        "def rmse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula el RMSE entre los valores verdaderos y predichos.\n",
        "    \"\"\"\n",
        "    # Convertir y_true a float32 para evitar problemas de tipo\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    # Evitar divisiones por cero añadiendo un pequeño epsilon\n",
        "    squared_error = K.square(y_pred - y_true)\n",
        "    mean_squared_error = K.mean(squared_error) + K.epsilon()\n",
        "    return K.sqrt(mean_squared_error)\n",
        "\n",
        "# Paso 2: Split características (X) y variable objetivo (y)\n",
        "X = train_df.drop(columns=['SalePrice'])  # Características\n",
        "y = train_df['SalePrice']                # Variable objetivo\n",
        "\n",
        "# Paso 3: Dividimos los datos en conjuntos de entrenamiento (80%) y validación (20%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Paso 4: Identificar variables numéricas\n",
        "numeric_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Eliminar columnas constantes\n",
        "constant_cols = [col for col in numeric_cols if X_train[col].nunique() == 1]\n",
        "numeric_cols = [col for col in numeric_cols if col not in constant_cols]\n",
        "print(f\"Columnas eliminadas por ser constantes: {constant_cols}\")\n",
        "\n",
        "# Ahora aplicar normalización min-max\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Transformar en X_train\n",
        "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
        "\n",
        "# Transformar en X_val usando los mismos parámetros\n",
        "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
        "\n",
        "# Convertir y_train y y_val a float32\n",
        "y_train = y_train.astype('float32')\n",
        "y_val = y_val.astype('float32')\n",
        "print(\"Tipos de datos en y_train y y_val después de la conversión:\")\n",
        "print(y_train.dtype, y_val.dtype)\n",
        "\n",
        "# Creación del modelo\n",
        "model = Sequential([\n",
        "    Dense(200, input_dim=X_train.shape[1], activation='relu'),  # Primera capa oculta\n",
        "    Dense(200, activation='relu'),                             # Segunda capa oculta\n",
        "    Dense(1)                                                  # Capa de salida para regresión\n",
        "])\n",
        "\n",
        "# Compilamos el modelo con RMSE como métrica\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Optimizador Adam con tasa de aprendizaje 0.001\n",
        "    loss='mse',                           # Función de pérdida: Error Cuadrático Medio (MSE)\n",
        "    metrics=[rmse]                       # Métrica personalizada: RMSE\n",
        ")\n",
        "\n",
        "# Ver un resumen del modelo\n",
        "model.summary()\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,          # Número de épocas\n",
        "    batch_size=32,       # Tamaño del lote\n",
        "    verbose=1            # Mostrar el progreso\n",
        ")\n",
        "\n",
        "# Evaluación del modelo en el conjunto de validación\n",
        "val_loss, val_rmse = model.evaluate(X_val, y_val, verbose=0)\n",
        "print(f\"\\nError RMSE en el conjunto de validación: {val_rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwwSq-7eQxPL"
      },
      "source": [
        "RMSE final en el conjunto de validación es 38,421.72 significativamente más bajo que los valores iniciales. El modelo ha logrado mejorar mucho durante el entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVW_OvnySCKT"
      },
      "source": [
        "# 10. Evaluar la predicción en Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8XVwRBXRWaU",
        "outputId": "b14bae64-ed81-49e0-8f7c-255910187913"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Primeras filas del conjunto de prueba (test_df):\n",
            "     Id  MSSubClass  LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "0  1000          20     6762            7            5          2006   \n",
            "1  1001          20    10206            3            3          1952   \n",
            "2  1002          30     5400            5            6          1950   \n",
            "3  1003          20    11957            8            5          2006   \n",
            "4  1004          90    11500            5            6          1976   \n",
            "\n",
            "   ExterQual  ExterCond  Foundation  BsmtFinSF1  ...  3SsnPorch  ScreenPorch  \\\n",
            "0          4          3           5         686  ...          0            0   \n",
            "1          3          3           1           0  ...          0            0   \n",
            "2          3          3           2           0  ...          0            0   \n",
            "3          4          3           5          24  ...          0            0   \n",
            "4          3          3           3           0  ...          0            0   \n",
            "\n",
            "   PoolArea  MiscVal  MoSold  SaleCondition  SalePrice  House_Age  \\\n",
            "0         0        0       2              5     206000          4   \n",
            "1         0        0       7              5      82000         57   \n",
            "2         0        0       1              3      86000         87   \n",
            "3         0        0       7              5     232000          2   \n",
            "4         0        0       6              5     136905         31   \n",
            "\n",
            "   House_Newness_Score  SaleConditionImpacto  \n",
            "0             0.818731                   1.0  \n",
            "1             0.057844                   1.0  \n",
            "2             0.012907                  -0.7  \n",
            "3             0.904837                   1.0  \n",
            "4             0.212248                   1.0  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "Estructura de X_test ajustada para coincidir con X_train.\n",
            "\n",
            "Normalización min-max aplicada correctamente a X_test.\n",
            "\n",
            "Primeras filas de X_test después de normalizar:\n",
            "       Id  MSSubClass  LotArea  OverallQual  OverallCond  YearRemodAdd  \\\n",
            "0  1000.0        20.0   6762.0          7.0          5.0        2006.0   \n",
            "1  1001.0        20.0  10206.0          3.0          3.0        1952.0   \n",
            "2  1002.0        30.0   5400.0          5.0          6.0        1950.0   \n",
            "3  1003.0        20.0  11957.0          8.0          5.0        2006.0   \n",
            "4  1004.0        90.0  11500.0          5.0          6.0        1976.0   \n",
            "\n",
            "   ExterQual  ExterCond  Foundation  BsmtFinSF1  ...  EnclosedPorch  \\\n",
            "0        4.0        3.0         5.0       686.0  ...            0.0   \n",
            "1        3.0        3.0         1.0         0.0  ...            0.0   \n",
            "2        3.0        3.0         2.0         0.0  ...           94.0   \n",
            "3        4.0        3.0         5.0        24.0  ...            0.0   \n",
            "4        3.0        3.0         3.0         0.0  ...            0.0   \n",
            "\n",
            "   3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  SaleCondition  \\\n",
            "0        0.0          0.0       0.0      0.0     2.0            5.0   \n",
            "1        0.0          0.0       0.0      0.0     7.0            5.0   \n",
            "2        0.0          0.0       0.0      0.0     1.0            3.0   \n",
            "3        0.0          0.0       0.0      0.0     7.0            5.0   \n",
            "4        0.0          0.0       0.0      0.0     6.0            5.0   \n",
            "\n",
            "   House_Age  House_Newness_Score  SaleConditionImpacto  \n",
            "0        4.0             0.818731                   1.0  \n",
            "1       57.0             0.057844                   1.0  \n",
            "2       87.0             0.012907                  -0.7  \n",
            "3        2.0             0.904837                   1.0  \n",
            "4       31.0             0.212248                   1.0  \n",
            "\n",
            "[5 rows x 44 columns]\n",
            "\n",
            "Tipos de datos en X_test:\n",
            "Id                      float64\n",
            "MSSubClass              float64\n",
            "LotArea                 float64\n",
            "OverallQual             float64\n",
            "OverallCond             float64\n",
            "YearRemodAdd            float64\n",
            "ExterQual               float64\n",
            "ExterCond               float64\n",
            "Foundation              float64\n",
            "BsmtFinSF1              float64\n",
            "BsmtFinSF2              float64\n",
            "BsmtUnfSF               float64\n",
            "TotalBsmtSF             float64\n",
            "HeatingQC               float64\n",
            "Electrical              float64\n",
            "1stFlrSF                float64\n",
            "2ndFlrSF                float64\n",
            "LowQualFinSF            float64\n",
            "GrLivArea               float64\n",
            "BsmtFullBath            float64\n",
            "BsmtHalfBath            float64\n",
            "FullBath                float64\n",
            "HalfBath                float64\n",
            "BedroomAbvGr            float64\n",
            "KitchenAbvGr            float64\n",
            "KitchenQual             float64\n",
            "TotRmsAbvGrd            float64\n",
            "Functional              float64\n",
            "Fireplaces              float64\n",
            "GarageCars              float64\n",
            "GarageArea              float64\n",
            "PavedDrive              float64\n",
            "WoodDeckSF              float64\n",
            "OpenPorchSF             float64\n",
            "EnclosedPorch           float64\n",
            "3SsnPorch               float64\n",
            "ScreenPorch             float64\n",
            "PoolArea                float64\n",
            "MiscVal                 float64\n",
            "MoSold                  float64\n",
            "SaleCondition           float64\n",
            "House_Age               float64\n",
            "House_Newness_Score     float64\n",
            "SaleConditionImpacto    float64\n",
            "dtype: object\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "\n",
            "Predicciones realizadas en el conjunto de prueba (primeras 5):\n",
            "[[3.2824112e+08]\n",
            " [3.4333123e+08]\n",
            " [2.2951939e+08]\n",
            " [4.8724205e+08]\n",
            " [4.7143930e+08]]\n",
            "\n",
            "Error RMSE en el conjunto de prueba: 447289568.00\n"
          ]
        }
      ],
      "source": [
        "# Cargamos las librerías generales\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Comprobamos que `test_df` esté correctamente cargado\n",
        "if 'test_df' not in locals():\n",
        "    raise ValueError(\"El conjunto de prueba (test_df) no está disponible. Por favor, asegúrate de cargarlo.\")\n",
        "\n",
        "print(\"Primeras filas del conjunto de prueba (test_df):\")\n",
        "print(test_df.head())\n",
        "\n",
        "# Split características (X_test)\n",
        "X_test = test_df.copy()  # Asegurarse de que X_test sea una copia independiente\n",
        "\n",
        "# Comprobar que X_test tenga las mismas columnas que X_train\n",
        "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
        "for col in missing_cols:\n",
        "    X_test[col] = 0  # Agregar columnas faltantes con valor 0\n",
        "\n",
        "# Reordenar las columnas de X_test para que coincidan con X_train\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "print(\"\\nEstructura de X_test ajustada para coincidir con X_train.\")\n",
        "\n",
        "# Normalización min-max a X_test\n",
        "numeric_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Nuevo MinMaxScaler y ajustarlo con X_train\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train[numeric_cols])  # Ajustar el escalador con los datos de entrenamiento\n",
        "\n",
        "# Transformar en X_test usando los mismos parámetros que se usaron para X_train\n",
        "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
        "\n",
        "print(\"\\nNormalización min-max aplicada correctamente a X_test.\")\n",
        "\n",
        "# Verificar los resultados después de la normalización\n",
        "print(\"\\nPrimeras filas de X_test después de normalizar:\")\n",
        "print(X_test.head())\n",
        "\n",
        "# Verificar tipos de datos en X_test\n",
        "print(\"\\nTipos de datos en X_test:\")\n",
        "print(X_test.dtypes)\n",
        "\n",
        "# Realizar la predicción en el conjunto de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"\\nPredicciones realizadas en el conjunto de prueba (primeras 5):\")\n",
        "print(y_pred[:5])\n",
        "\n",
        "# Si hay valores reales de `SalePrice` en test_df, evaluar el RMSE\n",
        "if 'SalePrice' in test_df.columns:\n",
        "    y_test = test_df['SalePrice'].values.astype('float32')  # Convertir a float32 si es necesario\n",
        "    test_rmse = np.sqrt(np.mean((y_pred.flatten() - y_test) ** 2))\n",
        "    print(f\"\\nError RMSE en el conjunto de prueba: {test_rmse:.2f}\")\n",
        "else:\n",
        "    print(\"\\nNo hay valores reales de SalePrice en test_df. No se puede calcular el RMSE.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXRSqDeiSOo3"
      },
      "source": [
        "# 11. Crear una arquitectura que produzca overfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "mms7BlyrSTIu",
        "outputId": "e3ee746b-e7eb-48da-da71-f178dcec7e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resumen del modelo con overfit:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">250,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,200</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">201</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │        \u001b[38;5;34m22,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)            │       \u001b[38;5;34m250,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m150,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m60,200\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m201\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">483,701</span> (1.85 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m483,701\u001b[0m (1.85 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">483,701</span> (1.85 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m483,701\u001b[0m (1.85 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 41046355968.0000 - mae: 185628.2500 - val_loss: 37844373504.0000 - val_mae: 176725.7656\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 37033844736.0000 - mae: 175949.2812 - val_loss: 25066414080.0000 - val_mae: 138857.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16344015872.0000 - mae: 103340.6641 - val_loss: 4823443968.0000 - val_mae: 61171.3906\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4366289408.0000 - mae: 48663.3750 - val_loss: 3076373504.0000 - val_mae: 40801.6406\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3082793216.0000 - mae: 41754.1367 - val_loss: 2856563456.0000 - val_mae: 35353.2500\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2828459008.0000 - mae: 35219.3008 - val_loss: 2614241280.0000 - val_mae: 36448.0273\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2226640384.0000 - mae: 34686.5195 - val_loss: 2401849088.0000 - val_mae: 34360.9258\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2281206784.0000 - mae: 33627.6875 - val_loss: 2208524288.0000 - val_mae: 33065.5469\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2218294272.0000 - mae: 32767.2617 - val_loss: 2043499264.0000 - val_mae: 28093.4258\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2126716800.0000 - mae: 30978.0762 - val_loss: 1951534592.0000 - val_mae: 25697.5527\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1782626688.0000 - mae: 28609.3809 - val_loss: 1707243264.0000 - val_mae: 27614.8320\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 2050845824.0000 - mae: 29687.7656 - val_loss: 1579265920.0000 - val_mae: 26320.1699\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1706526592.0000 - mae: 27317.7305 - val_loss: 1463754752.0000 - val_mae: 23972.3555\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1293932416.0000 - mae: 23798.5547 - val_loss: 1377345408.0000 - val_mae: 23523.9043\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1766787584.0000 - mae: 25217.3770 - val_loss: 1343147264.0000 - val_mae: 22604.9434\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1346025728.0000 - mae: 23301.9473 - val_loss: 1273398016.0000 - val_mae: 22709.1992\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 1170145024.0000 - mae: 23064.8906 - val_loss: 1221372288.0000 - val_mae: 22983.2969\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1196417152.0000 - mae: 22380.6094 - val_loss: 1188023040.0000 - val_mae: 22866.4746\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1127286784.0000 - mae: 22187.5254 - val_loss: 1199625088.0000 - val_mae: 22056.9141\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1165562752.0000 - mae: 22664.5488 - val_loss: 1225610368.0000 - val_mae: 22094.0957\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1121273344.0000 - mae: 21158.6855 - val_loss: 1112242432.0000 - val_mae: 22294.1602\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1322342400.0000 - mae: 23661.3535 - val_loss: 1092526592.0000 - val_mae: 21573.8809\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1004720576.0000 - mae: 21003.5332 - val_loss: 1095514496.0000 - val_mae: 22816.2402\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 926429888.0000 - mae: 20403.3438 - val_loss: 1056362432.0000 - val_mae: 21303.0352\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 879920192.0000 - mae: 20119.9844 - val_loss: 1059139968.0000 - val_mae: 20792.4121\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 810392128.0000 - mae: 19839.8867 - val_loss: 1026520320.0000 - val_mae: 21449.9082\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1025195456.0000 - mae: 20734.4531 - val_loss: 1095511296.0000 - val_mae: 21099.6641\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 937766144.0000 - mae: 20350.4746 - val_loss: 1072130560.0000 - val_mae: 20722.0156\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1097795712.0000 - mae: 20520.8105 - val_loss: 995378368.0000 - val_mae: 21028.7793\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 885733440.0000 - mae: 20835.2031 - val_loss: 998971776.0000 - val_mae: 20290.2168\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1104614912.0000 - mae: 20478.9453 - val_loss: 1025154432.0000 - val_mae: 20306.6367\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 990416384.0000 - mae: 19334.5977 - val_loss: 1004061952.0000 - val_mae: 20170.6875\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 994111744.0000 - mae: 19831.5879 - val_loss: 950284288.0000 - val_mae: 19940.1621\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 996102144.0000 - mae: 19310.8047 - val_loss: 940764352.0000 - val_mae: 20301.8652\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 763438912.0000 - mae: 19110.1113 - val_loss: 926634176.0000 - val_mae: 19908.4434\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 713046336.0000 - mae: 18664.0586 - val_loss: 1070439872.0000 - val_mae: 21021.5859\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 788754048.0000 - mae: 19670.2246 - val_loss: 1041280768.0000 - val_mae: 20529.7441\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 911964160.0000 - mae: 19102.8477 - val_loss: 979941696.0000 - val_mae: 19698.3340\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 854875200.0000 - mae: 19323.2578 - val_loss: 899722112.0000 - val_mae: 19822.2793\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 969129088.0000 - mae: 18697.9590 - val_loss: 950598528.0000 - val_mae: 19431.7891\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 1347739776.0000 - mae: 20171.1230 - val_loss: 919759424.0000 - val_mae: 19189.7070\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 752282112.0000 - mae: 18148.5352 - val_loss: 937483520.0000 - val_mae: 21230.1445\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 907963712.0000 - mae: 19947.1895 - val_loss: 880920320.0000 - val_mae: 18891.6406\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 722711808.0000 - mae: 17517.7598 - val_loss: 869708096.0000 - val_mae: 18800.3438\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 1264919680.0000 - mae: 18576.8164 - val_loss: 869955392.0000 - val_mae: 19589.4238\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 660964160.0000 - mae: 17903.6777 - val_loss: 947350336.0000 - val_mae: 19507.0879\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1108997376.0000 - mae: 18790.2363 - val_loss: 916075328.0000 - val_mae: 18856.3340\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 970859520.0000 - mae: 18108.1484 - val_loss: 860617344.0000 - val_mae: 18622.1055\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 792306048.0000 - mae: 17811.8398 - val_loss: 871494272.0000 - val_mae: 18624.9961\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1250936576.0000 - mae: 18628.0469 - val_loss: 881888384.0000 - val_mae: 18569.8965\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 791235456.0000 - mae: 18192.8496 - val_loss: 927913408.0000 - val_mae: 19300.9434\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 674743040.0000 - mae: 17396.8125 - val_loss: 896179968.0000 - val_mae: 18544.7031\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1105079168.0000 - mae: 17935.1562 - val_loss: 871203008.0000 - val_mae: 18533.2520\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 855871488.0000 - mae: 17352.1426 - val_loss: 881942464.0000 - val_mae: 18578.8047\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 855389312.0000 - mae: 17474.6367 - val_loss: 861438208.0000 - val_mae: 18364.3086\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 768230528.0000 - mae: 17635.7949 - val_loss: 852485952.0000 - val_mae: 19762.5742\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1267133568.0000 - mae: 18185.5898 - val_loss: 922755648.0000 - val_mae: 18851.8086\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 786422656.0000 - mae: 17607.2539 - val_loss: 824338368.0000 - val_mae: 18286.5781\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 728994816.0000 - mae: 17134.4414 - val_loss: 826735488.0000 - val_mae: 18260.8008\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 610449088.0000 - mae: 16315.8789 - val_loss: 905201024.0000 - val_mae: 18791.6855\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 825650048.0000 - mae: 17027.8262 - val_loss: 838317696.0000 - val_mae: 19537.7383\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 788820032.0000 - mae: 17389.2891 - val_loss: 840308800.0000 - val_mae: 19595.3711\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 738545024.0000 - mae: 17141.8594 - val_loss: 909017600.0000 - val_mae: 21443.9707\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 804848128.0000 - mae: 18102.3535 - val_loss: 810714560.0000 - val_mae: 18205.2910\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1049809600.0000 - mae: 17381.4609 - val_loss: 813298752.0000 - val_mae: 18200.2227\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 565291776.0000 - mae: 15460.6660 - val_loss: 809393792.0000 - val_mae: 18231.0059\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 564953216.0000 - mae: 15861.8896 - val_loss: 813596096.0000 - val_mae: 18727.0352\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 735967936.0000 - mae: 17384.2520 - val_loss: 818508096.0000 - val_mae: 19016.7246\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 992165056.0000 - mae: 17751.5938 - val_loss: 841794432.0000 - val_mae: 17999.9688\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 632632320.0000 - mae: 16212.4600 - val_loss: 832176512.0000 - val_mae: 17957.1250\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1091967744.0000 - mae: 18173.7090 - val_loss: 819824896.0000 - val_mae: 17900.2461\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1044412864.0000 - mae: 17606.0449 - val_loss: 816101376.0000 - val_mae: 17914.5762\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 604072512.0000 - mae: 16135.2930 - val_loss: 831524096.0000 - val_mae: 17870.5430\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 617632640.0000 - mae: 16793.7871 - val_loss: 891771776.0000 - val_mae: 18396.3477\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 543814848.0000 - mae: 15866.0107 - val_loss: 820015744.0000 - val_mae: 17807.1406\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 634955520.0000 - mae: 16103.6104 - val_loss: 806622080.0000 - val_mae: 17967.7031\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 866848832.0000 - mae: 16189.6328 - val_loss: 804342656.0000 - val_mae: 18208.4648\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 598066816.0000 - mae: 15847.7217 - val_loss: 936874560.0000 - val_mae: 18855.1543\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 937569728.0000 - mae: 16964.3398 - val_loss: 804482432.0000 - val_mae: 18047.7441\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1024002368.0000 - mae: 17170.2285 - val_loss: 805857664.0000 - val_mae: 17891.4102\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 789554816.0000 - mae: 16308.1768 - val_loss: 837124032.0000 - val_mae: 19737.7500\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 593089216.0000 - mae: 16056.5518 - val_loss: 802351424.0000 - val_mae: 18179.4160\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 805830336.0000 - mae: 16976.3750 - val_loss: 814766464.0000 - val_mae: 19122.1660\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 649185536.0000 - mae: 16417.5137 - val_loss: 806663680.0000 - val_mae: 17950.6777\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 605891712.0000 - mae: 15341.4766 - val_loss: 824835840.0000 - val_mae: 19488.2168\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 791324928.0000 - mae: 16630.4453 - val_loss: 800462592.0000 - val_mae: 18113.8984\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 529086400.0000 - mae: 15410.4385 - val_loss: 861165888.0000 - val_mae: 17902.7207\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 833318272.0000 - mae: 15857.7842 - val_loss: 813262208.0000 - val_mae: 18955.2109\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 524280384.0000 - mae: 15039.7979 - val_loss: 977106048.0000 - val_mae: 19521.0820\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 592375232.0000 - mae: 16353.8633 - val_loss: 879142912.0000 - val_mae: 18050.1621\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 975322432.0000 - mae: 17158.1406 - val_loss: 830521664.0000 - val_mae: 17671.0195\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 602957760.0000 - mae: 15467.1494 - val_loss: 795533504.0000 - val_mae: 18061.8008\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 772154688.0000 - mae: 16321.8096 - val_loss: 824850624.0000 - val_mae: 19434.3867\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 805588416.0000 - mae: 17210.7773 - val_loss: 804200128.0000 - val_mae: 18522.7891\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 618134976.0000 - mae: 16594.2695 - val_loss: 1020806592.0000 - val_mae: 19939.0312\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 523061280.0000 - mae: 15855.8486 - val_loss: 831789248.0000 - val_mae: 17653.2070\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 872075456.0000 - mae: 16618.6699 - val_loss: 817174720.0000 - val_mae: 17642.6074\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 845343552.0000 - mae: 15789.9268 - val_loss: 830651136.0000 - val_mae: 19704.4570\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1108960256.0000 - mae: 18459.7383 - val_loss: 813065280.0000 - val_mae: 17593.4297\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 533387744.0000 - mae: 14484.1221 - val_loss: 883882560.0000 - val_mae: 18058.0547\n",
            "\n",
            "Pérdida en el conjunto de validación (MSE): 883882560.00\n",
            "Error Absoluto Medio (MAE) en el conjunto de validación: 18058.05\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Librerías generales\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Definimos la arquitectura del modelo (complejo para que se provoque el overfit)\n",
        "model_overfit = Sequential()\n",
        "\n",
        "# Capa de entrada y primera capa oculta (más neuronas para incrementar la capacidad del modelo)\n",
        "model_overfit.add(Dense(500, input_dim=X_train.shape[1], activation='relu'))  # 500 neuronas\n",
        "\n",
        "# Segunda capa oculta (más neuronas para incrementar la complejidad)\n",
        "model_overfit.add(Dense(500, activation='relu'))  # 500 neuronas\n",
        "\n",
        "# Tercera capa oculta (aún mayor complejidad)\n",
        "model_overfit.add(Dense(300, activation='relu'))  # 300 neuronas\n",
        "\n",
        "# Cuarta capa oculta (capa adicional para incrementar la capacidad)\n",
        "model_overfit.add(Dense(200, activation='relu'))  # 200 neuronas\n",
        "\n",
        "# Capa de salida (1 neurona, sin función de activación porque es regresión)\n",
        "model_overfit.add(Dense(1))\n",
        "\n",
        "# Compilar el modelo\n",
        "model_overfit.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Optimizador Adam con tasa de aprendizaje 0.001\n",
        "    loss='mse',                          # Función de pérdida: Error Cuadrático Medio (MSE)\n",
        "    metrics=['mae']                      # Medidas: Error Absoluto Medio (MAE)\n",
        ")\n",
        "\n",
        "# Resumen del modelo\n",
        "print(\"\\nResumen del modelo con overfit:\")\n",
        "model_overfit.summary()\n",
        "\n",
        "# Entrenamiento  del modelo\n",
        "history_overfit = model_overfit.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,          # Número de épocas\n",
        "    batch_size=32,       # Tamaño del lote\n",
        "    verbose=1            # Mostrar el progreso\n",
        ")\n",
        "\n",
        "# Evaluación del modelo dentro del conjunto de validación\n",
        "# Se asignan los resultados de la evaluación a variables específicas\n",
        "val_loss_overfit, val_mae_overfit = model_overfit.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "# Print de los resultados de la evaluación\n",
        "print(f\"\\nPérdida en el conjunto de validación (MSE): {val_loss_overfit:.2f}\")\n",
        "print(f\"Error Absoluto Medio (MAE) en el conjunto de validación: {val_mae_overfit:.2f}\")\n",
        "\n",
        "# Representación gráfica de la pérdida durante el entrenamiento\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history_overfit.history['loss'], label='Pérdida en entrenamiento')\n",
        "plt.plot(history_overfit.history['val_loss'], label='Pérdida en validación')\n",
        "plt.title('Pérdida durante el entrenamiento (Overfit)')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida (MSE)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e41b0oNQSgZm"
      },
      "source": [
        "# El gráfico muestra cómo la pérdida en entrenamiento cae rápidamente, mientras que la pérdida en validación comienza a aumentar, lo cual es un indicador de la presencia de overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8s7MKwSSkVo"
      },
      "source": [
        "#12. Probar 3 ejemplos con distintas regularizaciones y identificar la que mejor funciona"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhvs1utQZGA6"
      },
      "source": [
        "Para resolver el ejericio 12, vamos a probar con tres regularizaciones e identificaremos cual funciona mejor.\n",
        "\n",
        "\n",
        "1.   Regularización L2 (Ridge): Penaliza los pesos grandes del modelo mediante una penalización proporcional al cuadrado de los pesos. Conviene para reducir el overfitting sin eliminar características.\n",
        "2.   Regularización L1 (Lasso): Castiga pesos grandes mediante una penalización proporcional al valor absoluto de los pesos. Elimina características irrelevantes al forzar algunos pesos a cero.\n",
        "3.   Dropout: técnica específica de redes neuronales que desactiva aleatoriamente neuronas durante el entrenamiento para evitar que el modelo dependa demasiado de determinadas neuronas.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi05kp8NSsQy",
        "outputId": "234143c8-a655-4edd-a0a6-7e240a31b80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando modelo con regularización: L2\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 41139232768.0000 - mae: 186545.8281 - val_loss: 38224072704.0000 - val_mae: 177735.0469\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 39998074880.0000 - mae: 182495.6250 - val_loss: 38190039040.0000 - val_mae: 177645.2344\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 41043152896.0000 - mae: 183859.1562 - val_loss: 38077104128.0000 - val_mae: 177346.8438\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 40320438272.0000 - mae: 182749.5781 - val_loss: 37812989952.0000 - val_mae: 176647.1562\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 38933630976.0000 - mae: 181312.2812 - val_loss: 37316243456.0000 - val_mae: 175323.9844\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40372609024.0000 - mae: 184199.8125 - val_loss: 36503261184.0000 - val_mae: 173137.4219\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37597794304.0000 - mae: 178710.3438 - val_loss: 35296419840.0000 - val_mae: 169841.7188\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 36365623296.0000 - mae: 173978.6562 - val_loss: 33639841792.0000 - val_mae: 165214.9688\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33775077376.0000 - mae: 167889.1094 - val_loss: 31515848704.0000 - val_mae: 159093.7188\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 32989517824.0000 - mae: 163554.5000 - val_loss: 28930447360.0000 - val_mae: 151323.7500\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 29105225728.0000 - mae: 153384.6094 - val_loss: 25938925568.0000 - val_mae: 141825.2344\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26775646208.0000 - mae: 145567.3281 - val_loss: 22642386944.0000 - val_mae: 130600.4766\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 23174719488.0000 - mae: 133555.6719 - val_loss: 19193145344.0000 - val_mae: 117811.0781\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19564208128.0000 - mae: 120277.7656 - val_loss: 15784894464.0000 - val_mae: 103792.7500\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15387959296.0000 - mae: 103167.2812 - val_loss: 12609129472.0000 - val_mae: 88992.5781\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12565855232.0000 - mae: 88258.3984 - val_loss: 9816101888.0000 - val_mae: 74072.1328\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10326913024.0000 - mae: 76948.0078 - val_loss: 7484188160.0000 - val_mae: 59712.9258\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6282850816.0000 - mae: 55455.5000 - val_loss: 5811089408.0000 - val_mae: 48311.4414\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6217911296.0000 - mae: 49537.6953 - val_loss: 4603936256.0000 - val_mae: 40678.3711\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4313990656.0000 - mae: 40271.1016 - val_loss: 3910606592.0000 - val_mae: 37337.2969\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4175485440.0000 - mae: 39364.6797 - val_loss: 3511125504.0000 - val_mae: 36997.9102\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3448688128.0000 - mae: 38863.1914 - val_loss: 3329836288.0000 - val_mae: 37947.1328\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3396885760.0000 - mae: 38597.0117 - val_loss: 3247868416.0000 - val_mae: 38839.5156\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3638429696.0000 - mae: 39748.5000 - val_loss: 3205611520.0000 - val_mae: 39544.5898\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3111120128.0000 - mae: 39525.3359 - val_loss: 3181114368.0000 - val_mae: 39850.4492\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3767538176.0000 - mae: 40582.8164 - val_loss: 3159869696.0000 - val_mae: 39814.0977\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2970887424.0000 - mae: 38880.4922 - val_loss: 3139348992.0000 - val_mae: 39809.3672\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3369245184.0000 - mae: 39364.8594 - val_loss: 3118299648.0000 - val_mae: 39867.4023\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3245053184.0000 - mae: 39946.2500 - val_loss: 3096425984.0000 - val_mae: 39665.9258\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3042254592.0000 - mae: 39567.9258 - val_loss: 3073814272.0000 - val_mae: 39474.8125\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2928960256.0000 - mae: 38904.0195 - val_loss: 3051955200.0000 - val_mae: 39349.9492\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2780647936.0000 - mae: 37941.1133 - val_loss: 3030355200.0000 - val_mae: 39233.8984\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2793724928.0000 - mae: 38555.6914 - val_loss: 3008065024.0000 - val_mae: 38973.6523\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3240604928.0000 - mae: 39776.2422 - val_loss: 2985029376.0000 - val_mae: 38743.2305\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3234831872.0000 - mae: 38038.0352 - val_loss: 2963653632.0000 - val_mae: 38689.8711\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3145296896.0000 - mae: 38707.0312 - val_loss: 2941484288.0000 - val_mae: 38488.6328\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3632527360.0000 - mae: 40144.3008 - val_loss: 2918620928.0000 - val_mae: 38286.2812\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3232902912.0000 - mae: 38325.5938 - val_loss: 2896313088.0000 - val_mae: 38056.2773\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3205479424.0000 - mae: 38378.6914 - val_loss: 2873463296.0000 - val_mae: 37879.7617\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2638724608.0000 - mae: 37560.1836 - val_loss: 2850445312.0000 - val_mae: 37583.5859\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 2757127936.0000 - mae: 37455.1133 - val_loss: 2828401920.0000 - val_mae: 37535.1641\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2808628736.0000 - mae: 38726.0977 - val_loss: 2805499136.0000 - val_mae: 37302.6523\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2918542336.0000 - mae: 38097.7227 - val_loss: 2783531264.0000 - val_mae: 37204.2852\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2314965504.0000 - mae: 35436.9688 - val_loss: 2760457216.0000 - val_mae: 36697.3672\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2938875136.0000 - mae: 37038.6719 - val_loss: 2738412032.0000 - val_mae: 36705.7344\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2627742720.0000 - mae: 35831.3008 - val_loss: 2716269056.0000 - val_mae: 36577.0742\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2959976960.0000 - mae: 38642.1094 - val_loss: 2693831680.0000 - val_mae: 36420.8633\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2957219840.0000 - mae: 37554.4141 - val_loss: 2670076160.0000 - val_mae: 36082.5156\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2490551040.0000 - mae: 35315.6250 - val_loss: 2647783424.0000 - val_mae: 35687.5312\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2688309504.0000 - mae: 35650.3867 - val_loss: 2624975616.0000 - val_mae: 35646.1094\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2631894528.0000 - mae: 36321.6250 - val_loss: 2602814208.0000 - val_mae: 35420.0586\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2317887232.0000 - mae: 34551.9492 - val_loss: 2580649984.0000 - val_mae: 35201.3633\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2431797504.0000 - mae: 35339.3789 - val_loss: 2558351616.0000 - val_mae: 35158.1836\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2791061248.0000 - mae: 36540.4258 - val_loss: 2535298560.0000 - val_mae: 34935.6133\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2312130048.0000 - mae: 34848.8867 - val_loss: 2513740800.0000 - val_mae: 34345.6406\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2353867264.0000 - mae: 34372.7773 - val_loss: 2490926592.0000 - val_mae: 34445.7617\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2871959040.0000 - mae: 36568.3867 - val_loss: 2469299200.0000 - val_mae: 34273.2656\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2035417728.0000 - mae: 32968.6094 - val_loss: 2447218688.0000 - val_mae: 33920.3516\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2408377088.0000 - mae: 34302.0391 - val_loss: 2425048064.0000 - val_mae: 33923.8047\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2766452224.0000 - mae: 36160.6211 - val_loss: 2402865664.0000 - val_mae: 33649.7656\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3510092288.0000 - mae: 38032.3359 - val_loss: 2380153856.0000 - val_mae: 33395.5625\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2750240512.0000 - mae: 36266.6172 - val_loss: 2358023168.0000 - val_mae: 33120.8477\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2523254272.0000 - mae: 34508.5078 - val_loss: 2336314368.0000 - val_mae: 32945.2930\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2193365504.0000 - mae: 32569.0996 - val_loss: 2315682560.0000 - val_mae: 32620.6973\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2377928704.0000 - mae: 34071.9219 - val_loss: 2293480960.0000 - val_mae: 32545.6777\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2633687296.0000 - mae: 34230.4648 - val_loss: 2271704064.0000 - val_mae: 32386.0723\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1778707584.0000 - mae: 30584.0801 - val_loss: 2251082240.0000 - val_mae: 31934.8730\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2544569856.0000 - mae: 33453.6367 - val_loss: 2229544704.0000 - val_mae: 32246.8652\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1876024832.0000 - mae: 31169.5215 - val_loss: 2209467136.0000 - val_mae: 31370.1855\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2101995008.0000 - mae: 30441.1484 - val_loss: 2187683328.0000 - val_mae: 31396.0156\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2216974080.0000 - mae: 32912.8281 - val_loss: 2166209280.0000 - val_mae: 31604.7832\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2465533184.0000 - mae: 32702.9980 - val_loss: 2144647040.0000 - val_mae: 31185.9004\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2382556416.0000 - mae: 33046.5430 - val_loss: 2123292544.0000 - val_mae: 30804.0625\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2512895232.0000 - mae: 33732.9648 - val_loss: 2103036288.0000 - val_mae: 30576.9199\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2311153664.0000 - mae: 33470.1719 - val_loss: 2083295360.0000 - val_mae: 30204.9395\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1888783616.0000 - mae: 29988.1621 - val_loss: 2063742720.0000 - val_mae: 29972.1992\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1808497408.0000 - mae: 29316.0117 - val_loss: 2043973632.0000 - val_mae: 29849.3594\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2474610176.0000 - mae: 31975.3418 - val_loss: 2023081600.0000 - val_mae: 29825.6367\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2058927744.0000 - mae: 31156.7344 - val_loss: 2004471808.0000 - val_mae: 29268.4902\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1609112832.0000 - mae: 28591.0469 - val_loss: 1984254080.0000 - val_mae: 29197.7246\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1885236224.0000 - mae: 29801.5449 - val_loss: 1964190720.0000 - val_mae: 29055.6230\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2285731840.0000 - mae: 30890.6113 - val_loss: 1945379200.0000 - val_mae: 28888.9492\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2405971968.0000 - mae: 32706.3789 - val_loss: 1926519168.0000 - val_mae: 28545.5547\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2021056896.0000 - mae: 29004.5137 - val_loss: 1908463360.0000 - val_mae: 28145.6523\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2006754304.0000 - mae: 30752.0527 - val_loss: 1889407360.0000 - val_mae: 28087.9297\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2135348096.0000 - mae: 30067.8145 - val_loss: 1870042752.0000 - val_mae: 28022.7656\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1811483392.0000 - mae: 28968.2031 - val_loss: 1853943680.0000 - val_mae: 27484.8203\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2328226048.0000 - mae: 31354.9629 - val_loss: 1833356544.0000 - val_mae: 27753.4258\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1602038272.0000 - mae: 28141.0332 - val_loss: 1819559552.0000 - val_mae: 27004.4492\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1639306624.0000 - mae: 27166.5098 - val_loss: 1800017024.0000 - val_mae: 27041.1641\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1733974272.0000 - mae: 28154.7695 - val_loss: 1782984576.0000 - val_mae: 26875.3066\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1664726144.0000 - mae: 28293.2246 - val_loss: 1767757440.0000 - val_mae: 26460.6504\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1895855872.0000 - mae: 29206.0117 - val_loss: 1748531712.0000 - val_mae: 26622.7402\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1513527296.0000 - mae: 27544.0215 - val_loss: 1731785856.0000 - val_mae: 26535.6934\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1578729344.0000 - mae: 28214.6855 - val_loss: 1716699136.0000 - val_mae: 26119.1367\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1868906496.0000 - mae: 28852.2832 - val_loss: 1698879616.0000 - val_mae: 26212.6797\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1651774976.0000 - mae: 27384.3223 - val_loss: 1686156416.0000 - val_mae: 25668.4102\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2373040384.0000 - mae: 29113.9590 - val_loss: 1669045504.0000 - val_mae: 25675.8184\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1732976384.0000 - mae: 27126.7031 - val_loss: 1658083072.0000 - val_mae: 25233.6699\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1661811456.0000 - mae: 26399.3711 - val_loss: 1639026048.0000 - val_mae: 25567.0645\n",
            "Resultado para L2:\n",
            "Pérdida en validación (MSE): 1639026048.00\n",
            "Error Absoluto Medio (MAE) en validación: 25567.06\n",
            "\n",
            "Entrenando modelo con regularización: L1\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 41811501056.0000 - mae: 185789.9062 - val_loss: 38224613376.0000 - val_mae: 177736.4219\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 41392209920.0000 - mae: 185691.7500 - val_loss: 38193254400.0000 - val_mae: 177653.5781\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 37649108992.0000 - mae: 179198.1094 - val_loss: 38086578176.0000 - val_mae: 177371.5781\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40537985024.0000 - mae: 183864.3438 - val_loss: 37831598080.0000 - val_mae: 176696.0781\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 37391945728.0000 - mae: 177225.9062 - val_loss: 37339717632.0000 - val_mae: 175386.0938\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 39549992960.0000 - mae: 181389.2188 - val_loss: 36497334272.0000 - val_mae: 173120.6562\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 37577179136.0000 - mae: 178298.0000 - val_loss: 35231485952.0000 - val_mae: 169661.5000\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34607022080.0000 - mae: 169789.6562 - val_loss: 33480050688.0000 - val_mae: 164760.2031\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 33488240640.0000 - mae: 165853.8906 - val_loss: 31185541120.0000 - val_mae: 158119.5469\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31947610112.0000 - mae: 162934.3438 - val_loss: 28432420864.0000 - val_mae: 149779.0156\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28238080000.0000 - mae: 151385.4688 - val_loss: 25266458624.0000 - val_mae: 139601.4844\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 26020485120.0000 - mae: 143706.9062 - val_loss: 21768198144.0000 - val_mae: 127462.4297\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 22837250048.0000 - mae: 129246.0469 - val_loss: 18223079424.0000 - val_mae: 113976.6875\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17590337536.0000 - mae: 115063.9922 - val_loss: 14705930240.0000 - val_mae: 98987.1016\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15218606080.0000 - mae: 101103.9766 - val_loss: 11514587136.0000 - val_mae: 83376.0781\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11416103936.0000 - mae: 83644.8672 - val_loss: 8821496832.0000 - val_mae: 68231.6406\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7936597504.0000 - mae: 66338.8125 - val_loss: 6751326208.0000 - val_mae: 54791.6406\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6146196992.0000 - mae: 52172.7383 - val_loss: 5217049088.0000 - val_mae: 44427.5234\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5568200704.0000 - mae: 44355.6094 - val_loss: 4241176320.0000 - val_mae: 38699.2617\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 5295500800.0000 - mae: 43010.9648 - val_loss: 3690804736.0000 - val_mae: 36917.1680\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3379830784.0000 - mae: 36769.3672 - val_loss: 3421979648.0000 - val_mae: 37390.0117\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3920218624.0000 - mae: 40652.2617 - val_loss: 3296450048.0000 - val_mae: 38278.1016\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2796210176.0000 - mae: 35248.1445 - val_loss: 3235834368.0000 - val_mae: 39001.3906\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3953249792.0000 - mae: 41840.4609 - val_loss: 3195925504.0000 - val_mae: 39751.3750\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3404834560.0000 - mae: 40357.3867 - val_loss: 3174612736.0000 - val_mae: 39746.0000\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3024179712.0000 - mae: 38189.4258 - val_loss: 3153495296.0000 - val_mae: 39891.7852\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3236263168.0000 - mae: 39607.3672 - val_loss: 3131838976.0000 - val_mae: 39863.8828\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2668523520.0000 - mae: 37916.2695 - val_loss: 3110213120.0000 - val_mae: 39556.1406\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2693395456.0000 - mae: 37867.2578 - val_loss: 3089181952.0000 - val_mae: 39609.1758\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3290165760.0000 - mae: 40874.9492 - val_loss: 3067873792.0000 - val_mae: 39612.5117\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3059305216.0000 - mae: 39637.8438 - val_loss: 3043960320.0000 - val_mae: 39221.1992\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3214261504.0000 - mae: 39353.9961 - val_loss: 3022535936.0000 - val_mae: 39203.1641\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3174020608.0000 - mae: 39586.3164 - val_loss: 2999750400.0000 - val_mae: 38989.6914\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2381209088.0000 - mae: 36170.2500 - val_loss: 2977464064.0000 - val_mae: 38656.6484\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3670631936.0000 - mae: 38702.9180 - val_loss: 2954540544.0000 - val_mae: 38528.0781\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3600852736.0000 - mae: 39499.0547 - val_loss: 2931991808.0000 - val_mae: 38371.9141\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2756409344.0000 - mae: 36824.6172 - val_loss: 2910027520.0000 - val_mae: 38245.2344\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2963693056.0000 - mae: 38726.4844 - val_loss: 2887064320.0000 - val_mae: 37953.6562\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2577243904.0000 - mae: 37066.5703 - val_loss: 2864357120.0000 - val_mae: 37779.7617\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2209925632.0000 - mae: 34024.7188 - val_loss: 2842106880.0000 - val_mae: 37540.6172\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2903525632.0000 - mae: 39403.5664 - val_loss: 2819487232.0000 - val_mae: 37516.8984\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3974886912.0000 - mae: 41464.5898 - val_loss: 2796108288.0000 - val_mae: 37340.1914\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3172261888.0000 - mae: 37551.1992 - val_loss: 2772988416.0000 - val_mae: 36949.7734\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2847624704.0000 - mae: 37317.3203 - val_loss: 2750384640.0000 - val_mae: 36784.8633\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2562782976.0000 - mae: 36588.6602 - val_loss: 2727483904.0000 - val_mae: 36541.2969\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2587087104.0000 - mae: 35842.9141 - val_loss: 2704755456.0000 - val_mae: 36302.7734\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2602648320.0000 - mae: 36276.4375 - val_loss: 2681968128.0000 - val_mae: 36149.9648\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2684132096.0000 - mae: 36214.8320 - val_loss: 2658581504.0000 - val_mae: 35876.3828\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2498099200.0000 - mae: 35433.0352 - val_loss: 2636961792.0000 - val_mae: 35996.1406\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3063964160.0000 - mae: 38538.5820 - val_loss: 2612638720.0000 - val_mae: 35736.8008\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2512153856.0000 - mae: 36214.4258 - val_loss: 2588898048.0000 - val_mae: 35296.5508\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2695612928.0000 - mae: 35622.3633 - val_loss: 2565614592.0000 - val_mae: 34972.0938\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2390638592.0000 - mae: 35597.1875 - val_loss: 2542946560.0000 - val_mae: 34892.8984\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2701004288.0000 - mae: 36065.6211 - val_loss: 2519998976.0000 - val_mae: 34854.5430\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3339816448.0000 - mae: 38006.2422 - val_loss: 2496068096.0000 - val_mae: 34551.3906\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1951828864.0000 - mae: 32790.6758 - val_loss: 2474240512.0000 - val_mae: 34202.3516\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2995571200.0000 - mae: 36076.6680 - val_loss: 2450731520.0000 - val_mae: 34108.2344\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2269757952.0000 - mae: 33690.0273 - val_loss: 2428660992.0000 - val_mae: 33676.5234\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2002910464.0000 - mae: 32694.9570 - val_loss: 2406231040.0000 - val_mae: 33622.9062\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2269047808.0000 - mae: 33113.7695 - val_loss: 2384006912.0000 - val_mae: 33490.0742\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2582585600.0000 - mae: 36054.0703 - val_loss: 2361552384.0000 - val_mae: 33566.2148\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2405344768.0000 - mae: 33869.6602 - val_loss: 2337954304.0000 - val_mae: 33009.6719\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2447254272.0000 - mae: 34653.5664 - val_loss: 2315885056.0000 - val_mae: 32690.3594\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2831100928.0000 - mae: 34944.9219 - val_loss: 2293836288.0000 - val_mae: 32738.0020\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2197822464.0000 - mae: 33373.7578 - val_loss: 2271854336.0000 - val_mae: 32274.8145\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2425765632.0000 - mae: 32982.7109 - val_loss: 2249769728.0000 - val_mae: 32094.5801\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2328059392.0000 - mae: 33589.2148 - val_loss: 2227788032.0000 - val_mae: 32005.9102\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1960254720.0000 - mae: 30667.0508 - val_loss: 2206348032.0000 - val_mae: 31670.7070\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2126166016.0000 - mae: 32102.0156 - val_loss: 2183790336.0000 - val_mae: 31484.2324\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2435992064.0000 - mae: 32969.9844 - val_loss: 2162269440.0000 - val_mae: 31266.6270\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2068357248.0000 - mae: 31782.4414 - val_loss: 2141748736.0000 - val_mae: 30986.2070\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1968363264.0000 - mae: 31828.7422 - val_loss: 2120934144.0000 - val_mae: 30682.6855\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2364868608.0000 - mae: 31534.2051 - val_loss: 2099584000.0000 - val_mae: 30694.6094\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2126745856.0000 - mae: 31026.7168 - val_loss: 2078774528.0000 - val_mae: 30232.7324\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1897925888.0000 - mae: 31096.3008 - val_loss: 2058715264.0000 - val_mae: 29986.5117\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2155814912.0000 - mae: 32238.9551 - val_loss: 2036782720.0000 - val_mae: 29804.2148\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2215016192.0000 - mae: 31884.8711 - val_loss: 2016313856.0000 - val_mae: 29588.5176\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2244476160.0000 - mae: 31983.8027 - val_loss: 1995997568.0000 - val_mae: 29387.5332\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2101584256.0000 - mae: 30684.9980 - val_loss: 1977822592.0000 - val_mae: 28877.9023\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1966102144.0000 - mae: 31245.2676 - val_loss: 1956537344.0000 - val_mae: 29259.2168\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2395362048.0000 - mae: 32950.2031 - val_loss: 1936708736.0000 - val_mae: 28653.2109\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2034577792.0000 - mae: 29310.1328 - val_loss: 1922996992.0000 - val_mae: 27948.0449\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1800041984.0000 - mae: 28903.6484 - val_loss: 1900141952.0000 - val_mae: 28240.1973\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1683030528.0000 - mae: 28469.2676 - val_loss: 1881041664.0000 - val_mae: 28002.0508\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2171109376.0000 - mae: 31011.7480 - val_loss: 1860959488.0000 - val_mae: 28158.9707\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1813724288.0000 - mae: 28955.5801 - val_loss: 1844154368.0000 - val_mae: 27518.6055\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2051093376.0000 - mae: 30402.1816 - val_loss: 1824613376.0000 - val_mae: 27462.3203\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1967166976.0000 - mae: 29214.8652 - val_loss: 1808668928.0000 - val_mae: 27047.6016\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1702166144.0000 - mae: 28134.1465 - val_loss: 1789359360.0000 - val_mae: 27111.8594\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1796811520.0000 - mae: 29356.6016 - val_loss: 1776505984.0000 - val_mae: 26487.3184\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1631987200.0000 - mae: 26992.1758 - val_loss: 1756635648.0000 - val_mae: 26607.5723\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1725962240.0000 - mae: 27526.3535 - val_loss: 1740030720.0000 - val_mae: 26360.5430\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1516067584.0000 - mae: 27273.9141 - val_loss: 1722007168.0000 - val_mae: 26653.8320\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1803285760.0000 - mae: 28649.1758 - val_loss: 1706358272.0000 - val_mae: 26038.1250\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1879820928.0000 - mae: 28020.4355 - val_loss: 1688719744.0000 - val_mae: 26048.5020\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2525928960.0000 - mae: 31333.3359 - val_loss: 1674852608.0000 - val_mae: 25571.2207\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1977901312.0000 - mae: 27188.3965 - val_loss: 1659520896.0000 - val_mae: 25520.2559\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2225517824.0000 - mae: 27772.7930 - val_loss: 1644081152.0000 - val_mae: 25413.2578\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1766546432.0000 - mae: 27116.4668 - val_loss: 1630777216.0000 - val_mae: 25168.4668\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1857575296.0000 - mae: 27226.8438 - val_loss: 1615437440.0000 - val_mae: 25081.1875\n",
            "Resultado para L1:\n",
            "Pérdida en validación (MSE): 1615437440.00\n",
            "Error Absoluto Medio (MAE) en validación: 25081.19\n",
            "\n",
            "Entrenando modelo con regularización: DROPOUT\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 38853730304.0000 - mae: 182220.9062 - val_loss: 38223163392.0000 - val_mae: 177732.5156\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 39967567872.0000 - mae: 182784.0000 - val_loss: 38185517056.0000 - val_mae: 177632.9844\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 40945831936.0000 - mae: 184710.5312 - val_loss: 38064590848.0000 - val_mae: 177313.1250\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 39643820032.0000 - mae: 182399.1719 - val_loss: 37785444352.0000 - val_mae: 176572.8125\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 41617141760.0000 - mae: 185100.5156 - val_loss: 37260320768.0000 - val_mae: 175172.0469\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 37873577984.0000 - mae: 179075.8906 - val_loss: 36391190528.0000 - val_mae: 172830.1406\n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37230514176.0000 - mae: 175256.8125 - val_loss: 35100438528.0000 - val_mae: 169294.8750\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 37790273536.0000 - mae: 175668.0156 - val_loss: 33318674432.0000 - val_mae: 164295.3438\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 36307734528.0000 - mae: 171631.5469 - val_loss: 31048126464.0000 - val_mae: 157703.6719\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 31839408128.0000 - mae: 160660.0625 - val_loss: 28310456320.0000 - val_mae: 149386.7969\n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28899690496.0000 - mae: 152539.3125 - val_loss: 25168130048.0000 - val_mae: 139257.2656\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24230864896.0000 - mae: 138418.5000 - val_loss: 21743931392.0000 - val_mae: 127350.1875\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22069428224.0000 - mae: 128789.4297 - val_loss: 18195941376.0000 - val_mae: 113841.2422\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18507169792.0000 - mae: 114817.6719 - val_loss: 14792071168.0000 - val_mae: 99341.1328\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15952379904.0000 - mae: 102586.2734 - val_loss: 11629181952.0000 - val_mae: 83933.5938\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10129794048.0000 - mae: 81519.2109 - val_loss: 9018393600.0000 - val_mae: 69366.2266\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9395223552.0000 - mae: 68711.6875 - val_loss: 6877415424.0000 - val_mae: 55597.2461\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7089756672.0000 - mae: 58126.6797 - val_loss: 5360038912.0000 - val_mae: 45301.7109\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5662580736.0000 - mae: 46823.5117 - val_loss: 4376400384.0000 - val_mae: 39375.5117\n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4869258752.0000 - mae: 44547.3750 - val_loss: 3808320000.0000 - val_mae: 37114.6992\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 4778596864.0000 - mae: 42988.4648 - val_loss: 3509621248.0000 - val_mae: 37131.4297\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3980165632.0000 - mae: 41462.1523 - val_loss: 3359178752.0000 - val_mae: 37832.6211\n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3597339904.0000 - mae: 41362.1523 - val_loss: 3272427008.0000 - val_mae: 38586.1055\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3935774208.0000 - mae: 43663.2734 - val_loss: 3225409280.0000 - val_mae: 39128.0820\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3731743488.0000 - mae: 43691.3281 - val_loss: 3199483904.0000 - val_mae: 39186.8867\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3905473280.0000 - mae: 43403.1680 - val_loss: 3172236544.0000 - val_mae: 39466.3086\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3652884224.0000 - mae: 41230.5742 - val_loss: 3150143744.0000 - val_mae: 39574.6758\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3602809600.0000 - mae: 44696.7891 - val_loss: 3130500096.0000 - val_mae: 39121.4023\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3608198912.0000 - mae: 43264.1445 - val_loss: 3110276608.0000 - val_mae: 38860.0898\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3485267456.0000 - mae: 41291.9805 - val_loss: 3088760064.0000 - val_mae: 38790.1328\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3466464768.0000 - mae: 40482.4219 - val_loss: 3066929408.0000 - val_mae: 38687.1289\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4040054528.0000 - mae: 44066.5234 - val_loss: 3044325376.0000 - val_mae: 38688.9297\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3508588544.0000 - mae: 43239.3867 - val_loss: 3024467712.0000 - val_mae: 38338.5312\n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3708649216.0000 - mae: 44138.8633 - val_loss: 3003044608.0000 - val_mae: 38129.2461\n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3978781952.0000 - mae: 43575.8203 - val_loss: 2981112064.0000 - val_mae: 37992.4375\n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3679789568.0000 - mae: 41697.3047 - val_loss: 2960859904.0000 - val_mae: 37754.7109\n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3929606400.0000 - mae: 43021.6406 - val_loss: 2943892480.0000 - val_mae: 37357.2617\n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3179149824.0000 - mae: 40604.3867 - val_loss: 2928092416.0000 - val_mae: 36953.6250\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3249296128.0000 - mae: 39684.5625 - val_loss: 2900971264.0000 - val_mae: 37155.3906\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3350039552.0000 - mae: 41962.8203 - val_loss: 2879584000.0000 - val_mae: 37000.0391\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3131602688.0000 - mae: 40394.2422 - val_loss: 2856645120.0000 - val_mae: 37033.9258\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3219035136.0000 - mae: 40082.7266 - val_loss: 2837152768.0000 - val_mae: 36701.1406\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3634460416.0000 - mae: 42720.2734 - val_loss: 2812992768.0000 - val_mae: 36778.0039\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3348222208.0000 - mae: 40778.1055 - val_loss: 2792836864.0000 - val_mae: 36476.6719\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3160522240.0000 - mae: 40147.5469 - val_loss: 2772082944.0000 - val_mae: 36277.0586\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3302569472.0000 - mae: 41041.1133 - val_loss: 2751680768.0000 - val_mae: 35972.1953\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3482436352.0000 - mae: 41399.6758 - val_loss: 2731700224.0000 - val_mae: 35684.6289\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3619899904.0000 - mae: 40584.0312 - val_loss: 2711239936.0000 - val_mae: 35568.6914\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2755669248.0000 - mae: 38599.8320 - val_loss: 2691339264.0000 - val_mae: 35275.0078\n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2988693760.0000 - mae: 38398.4297 - val_loss: 2671442432.0000 - val_mae: 35025.2695\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3373838080.0000 - mae: 42161.7773 - val_loss: 2648869376.0000 - val_mae: 34924.0234\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3707179264.0000 - mae: 40113.9961 - val_loss: 2628407040.0000 - val_mae: 34730.6914\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2913751040.0000 - mae: 38338.1250 - val_loss: 2609630464.0000 - val_mae: 34470.2617\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2854992384.0000 - mae: 37511.0742 - val_loss: 2588839168.0000 - val_mae: 34298.4766\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3585903360.0000 - mae: 41773.4688 - val_loss: 2565185792.0000 - val_mae: 34314.9141\n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2662811648.0000 - mae: 37223.9531 - val_loss: 2548811264.0000 - val_mae: 33978.1094\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2876773888.0000 - mae: 37826.7266 - val_loss: 2524134656.0000 - val_mae: 34106.3203\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3061497344.0000 - mae: 39068.2930 - val_loss: 2504009728.0000 - val_mae: 33860.2539\n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3415844352.0000 - mae: 40945.6875 - val_loss: 2491762688.0000 - val_mae: 33233.3984\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2819803136.0000 - mae: 37818.8672 - val_loss: 2472623616.0000 - val_mae: 32992.8164\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3041456128.0000 - mae: 37362.8828 - val_loss: 2448089088.0000 - val_mae: 33037.6641\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2501320448.0000 - mae: 35741.9180 - val_loss: 2431782656.0000 - val_mae: 32712.7949\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2742170624.0000 - mae: 36615.8672 - val_loss: 2406475520.0000 - val_mae: 32746.7520\n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3155622144.0000 - mae: 38985.0195 - val_loss: 2385612800.0000 - val_mae: 32637.9121\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2933943040.0000 - mae: 39082.5820 - val_loss: 2363899904.0000 - val_mae: 32606.8027\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2950884608.0000 - mae: 39057.0156 - val_loss: 2351584768.0000 - val_mae: 31943.6758\n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2782285568.0000 - mae: 36544.7773 - val_loss: 2326805760.0000 - val_mae: 32017.2051\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2818042880.0000 - mae: 37148.7578 - val_loss: 2310247936.0000 - val_mae: 31622.6758\n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2852316672.0000 - mae: 36825.7539 - val_loss: 2293126912.0000 - val_mae: 31313.7344\n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2415689472.0000 - mae: 34509.9062 - val_loss: 2273875200.0000 - val_mae: 31153.2402\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2808457728.0000 - mae: 36968.0000 - val_loss: 2247710464.0000 - val_mae: 31449.3105\n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2895619584.0000 - mae: 39526.3594 - val_loss: 2229981440.0000 - val_mae: 31074.2520\n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2865594368.0000 - mae: 36392.6406 - val_loss: 2213679872.0000 - val_mae: 30687.4492\n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2882862080.0000 - mae: 37188.3906 - val_loss: 2195507968.0000 - val_mae: 30473.8125\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2373276416.0000 - mae: 35410.9531 - val_loss: 2174019584.0000 - val_mae: 30454.1855\n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2898251264.0000 - mae: 36608.1250 - val_loss: 2154626048.0000 - val_mae: 30362.2949\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3006773760.0000 - mae: 37203.3438 - val_loss: 2133229952.0000 - val_mae: 30401.0020\n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2815687680.0000 - mae: 36234.9219 - val_loss: 2123907456.0000 - val_mae: 29593.0117\n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2829216256.0000 - mae: 36348.0508 - val_loss: 2102028416.0000 - val_mae: 29615.9902\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2446360832.0000 - mae: 35010.1641 - val_loss: 2085109760.0000 - val_mae: 29433.2051\n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2533700864.0000 - mae: 34080.8359 - val_loss: 2065148032.0000 - val_mae: 29467.7207\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2443510272.0000 - mae: 33361.5977 - val_loss: 2049853056.0000 - val_mae: 29103.2734\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2559640832.0000 - mae: 34020.7148 - val_loss: 2028315136.0000 - val_mae: 29211.5645\n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2416550144.0000 - mae: 34981.9531 - val_loss: 2012113920.0000 - val_mae: 28920.9102\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3210190080.0000 - mae: 36371.5859 - val_loss: 1996355072.0000 - val_mae: 28633.8457\n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2683017984.0000 - mae: 34457.9922 - val_loss: 1989563520.0000 - val_mae: 28004.9570\n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 3635824640.0000 - mae: 38210.6758 - val_loss: 1971880320.0000 - val_mae: 27841.7676\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2598960896.0000 - mae: 35322.0195 - val_loss: 1967704576.0000 - val_mae: 27324.9102\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2396133376.0000 - mae: 35416.2617 - val_loss: 1950582016.0000 - val_mae: 27213.4668\n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2740944640.0000 - mae: 33845.4414 - val_loss: 1921871744.0000 - val_mae: 27458.7793\n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2543289600.0000 - mae: 34234.7695 - val_loss: 1909956992.0000 - val_mae: 27202.2422\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2441081600.0000 - mae: 34211.1133 - val_loss: 1890395136.0000 - val_mae: 27154.0078\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2247184640.0000 - mae: 32489.1875 - val_loss: 1874516480.0000 - val_mae: 27038.7773\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1966990208.0000 - mae: 31639.9785 - val_loss: 1860077056.0000 - val_mae: 26854.4199\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2422259200.0000 - mae: 33420.6172 - val_loss: 1843480448.0000 - val_mae: 26804.4355\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2614599424.0000 - mae: 34247.1250 - val_loss: 1827905920.0000 - val_mae: 26622.6953\n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2600622080.0000 - mae: 34633.3281 - val_loss: 1811569920.0000 - val_mae: 26491.6230\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2209716736.0000 - mae: 32918.5820 - val_loss: 1795669248.0000 - val_mae: 26368.8008\n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2331304960.0000 - mae: 32814.0078 - val_loss: 1784877696.0000 - val_mae: 25994.2402\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1923809664.0000 - mae: 30940.4805 - val_loss: 1773164928.0000 - val_mae: 25792.9668\n",
            "Resultado para DROPOUT:\n",
            "Pérdida en validación (MSE): 1773164928.00\n",
            "Error Absoluto Medio (MAE) en validación: 25792.97\n",
            "\n",
            "Resumen de resultados:\n",
            "L2: Pérdida (MSE) = 1639026048.00, MAE = 25567.06\n",
            "L1: Pérdida (MSE) = 1615437440.00, MAE = 25081.19\n",
            "DROPOUT: Pérdida (MSE) = 1773164928.00, MAE = 25792.97\n",
            "\n",
            "Mejor regularización: L1 con pérdida (MSE) = 1615437440.00\n"
          ]
        }
      ],
      "source": [
        "# Recargamos las librerías generales anteriores\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Definimos una función para crear modelos con diferentes regularizaciones\n",
        "def create_model_with_regularization(reg_type=None, reg_param=0.01):\n",
        "    model = Sequential()\n",
        "\n",
        "    if reg_type == 'l2':\n",
        "        # Modelo con regularización L2\n",
        "        model.add(Dense(200, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(reg_param)))\n",
        "        model.add(Dense(200, activation='relu', kernel_regularizer=l2(reg_param)))\n",
        "    elif reg_type == 'l1':\n",
        "        # Modelo con regularización L1\n",
        "        model.add(Dense(200, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l1(reg_param)))\n",
        "        model.add(Dense(200, activation='relu', kernel_regularizer=l1(reg_param)))\n",
        "    elif reg_type == 'dropout':\n",
        "        # Modelo con Dropout\n",
        "        model.add(Dense(200, input_dim=X_train.shape[1], activation='relu'))\n",
        "        model.add(Dropout(0.5))  # Desactiva el 50% de las neuronas\n",
        "        model.add(Dense(200, activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "    else:\n",
        "        # Modelo base sin regularización\n",
        "        model.add(Dense(200, input_dim=X_train.shape[1], activation='relu'))\n",
        "        model.add(Dense(200, activation='relu'))\n",
        "\n",
        "    # Capa de salida\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compilamos el modelo\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Entrenamiento y evaluación de  cada modelo\n",
        "regularizations = ['l2', 'l1', 'dropout']\n",
        "results = {}\n",
        "\n",
        "for reg in regularizations:\n",
        "    print(f\"\\nEntrenando modelo con regularización: {reg.upper()}\")\n",
        "\n",
        "    # Creamos el modelo con la regularización correspondiente\n",
        "    model = create_model_with_regularization(reg_type=reg, reg_param=0.01)\n",
        "\n",
        "    # Entrenamiento\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluar sobre el conjunto de validación\n",
        "    val_loss, val_mae = model.evaluate(X_val, y_val, verbose=0)\n",
        "    results[reg] = {\n",
        "        'val_loss': val_loss,\n",
        "        'val_mae': val_mae\n",
        "    }\n",
        "\n",
        "    print(f\"Resultado para {reg.upper()}:\")\n",
        "    print(f\"Pérdida en validación (MSE): {val_loss:.2f}\")\n",
        "    print(f\"Error Absoluto Medio (MAE) en validación: {val_mae:.2f}\")\n",
        "\n",
        "# Respuesta a la pregunta cuál es la regularización que funciona mejor\n",
        "best_reg = min(results, key=lambda k: results[k]['val_loss'])\n",
        "print(\"\\nResumen de resultados:\")\n",
        "for reg, metrics in results.items():\n",
        "    print(f\"{reg.upper()}: Pérdida (MSE) = {metrics['val_loss']:.2f}, MAE = {metrics['val_mae']:.2f}\")\n",
        "print(f\"\\nMejor regularización: {best_reg.upper()} con pérdida (MSE) = {results[best_reg]['val_loss']:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "W96Qar7MXX9K",
        "Pk5AkyRYZJuT",
        "GfDCNE7F0qIA",
        "e1ITvmcg1oen",
        "zWTQLlFP9-hw",
        "aILI5ghsCuLX",
        "2xQR5TcSJ9eJ",
        "YkvQ4yHKGXl9",
        "9Jv5rH1LLGGj",
        "D-8wqoSBLm3j",
        "HVW_OvnySCKT",
        "HXRSqDeiSOo3",
        "Y8s7MKwSSkVo"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
